{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26057,
                "ndcg_at_1": 0.26829,
                "ndcg_at_5": 0.24914,
                "ndcg_at_10": 0.26057,
                "ndcg_at_25": 0.27232,
                "ndcg_at_50": 0.28147,
                "ndcg_at_100": 0.2865,
                "map_at_1": 0.15935,
                "map_at_5": 0.2211,
                "map_at_10": 0.2282,
                "map_at_25": 0.23207,
                "map_at_50": 0.23351,
                "map_at_100": 0.23411,
                "Recall_at_1": 0.15935,
                "Recall_at_5": 0.25894,
                "Recall_at_10": 0.28525,
                "Recall_at_25": 0.32265,
                "Recall_at_50": 0.3637,
                "Recall_at_100": 0.3885,
                "precision_at_1": 0.26829,
                "precision_at_5": 0.09756,
                "precision_at_10": 0.05561,
                "precision_at_25": 0.02576,
                "precision_at_50": 0.01444,
                "precision_at_100": 0.00776,
                "mrr": 0.30628
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.25086,
                "ndcg_at_1": 0.19828,
                "ndcg_at_5": 0.22776,
                "ndcg_at_10": 0.25086,
                "ndcg_at_25": 0.28635,
                "ndcg_at_50": 0.31158,
                "ndcg_at_100": 0.33522,
                "map_at_1": 0.07348,
                "map_at_5": 0.17055,
                "map_at_10": 0.18716,
                "map_at_25": 0.19891,
                "map_at_50": 0.20524,
                "map_at_100": 0.20885,
                "Recall_at_1": 0.07348,
                "Recall_at_5": 0.24151,
                "Recall_at_10": 0.3118,
                "Recall_at_25": 0.41213,
                "Recall_at_50": 0.49555,
                "Recall_at_100": 0.58017,
                "precision_at_1": 0.19828,
                "precision_at_5": 0.1431,
                "precision_at_10": 0.09914,
                "precision_at_25": 0.05828,
                "precision_at_50": 0.03707,
                "precision_at_100": 0.02388,
                "mrr": 0.30694
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.30601,
                "ndcg_at_1": 0.24648,
                "ndcg_at_5": 0.26509,
                "ndcg_at_10": 0.30601,
                "ndcg_at_25": 0.33494,
                "ndcg_at_50": 0.35717,
                "ndcg_at_100": 0.37809,
                "map_at_1": 0.13979,
                "map_at_5": 0.21046,
                "map_at_10": 0.23036,
                "map_at_25": 0.24003,
                "map_at_50": 0.24445,
                "map_at_100": 0.2469,
                "Recall_at_1": 0.13979,
                "Recall_at_5": 0.30962,
                "Recall_at_10": 0.41514,
                "Recall_at_25": 0.51467,
                "Recall_at_50": 0.60986,
                "Recall_at_100": 0.72183,
                "precision_at_1": 0.24648,
                "precision_at_5": 0.10986,
                "precision_at_10": 0.07535,
                "precision_at_25": 0.03775,
                "precision_at_50": 0.02268,
                "precision_at_100": 0.01331,
                "mrr": 0.35788
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19848,
                "ndcg_at_1": 0.16505,
                "ndcg_at_5": 0.18293,
                "ndcg_at_10": 0.19848,
                "ndcg_at_25": 0.23365,
                "ndcg_at_50": 0.2535,
                "ndcg_at_100": 0.2795,
                "map_at_1": 0.07683,
                "map_at_5": 0.10967,
                "map_at_10": 0.1278,
                "map_at_25": 0.14619,
                "map_at_50": 0.1568,
                "map_at_100": 0.16389,
                "Recall_at_1": 0.07683,
                "Recall_at_5": 0.1431,
                "Recall_at_10": 0.21009,
                "Recall_at_25": 0.35848,
                "Recall_at_50": 0.43738,
                "Recall_at_100": 0.53645,
                "precision_at_1": 0.16505,
                "precision_at_5": 0.11456,
                "precision_at_10": 0.09612,
                "precision_at_25": 0.06951,
                "precision_at_50": 0.05087,
                "precision_at_100": 0.03447,
                "mrr": 0.2417
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.11214,
                "ndcg_at_1": 0.06931,
                "ndcg_at_5": 0.10135,
                "ndcg_at_10": 0.11214,
                "ndcg_at_25": 0.1392,
                "ndcg_at_50": 0.16071,
                "ndcg_at_100": 0.18233,
                "map_at_1": 0.00995,
                "map_at_5": 0.05639,
                "map_at_10": 0.06438,
                "map_at_25": 0.07521,
                "map_at_50": 0.0803,
                "map_at_100": 0.08355,
                "Recall_at_1": 0.00995,
                "Recall_at_5": 0.11045,
                "Recall_at_10": 0.14971,
                "Recall_at_25": 0.25345,
                "Recall_at_50": 0.3261,
                "Recall_at_100": 0.41417,
                "precision_at_1": 0.06931,
                "precision_at_5": 0.07327,
                "precision_at_10": 0.05644,
                "precision_at_25": 0.03881,
                "precision_at_50": 0.02733,
                "precision_at_100": 0.01851,
                "mrr": 0.14479
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.24793,
                "ndcg_at_1": 0.18812,
                "ndcg_at_5": 0.22226,
                "ndcg_at_10": 0.24793,
                "ndcg_at_25": 0.27639,
                "ndcg_at_50": 0.30524,
                "ndcg_at_100": 0.33332,
                "map_at_1": 0.08328,
                "map_at_5": 0.14382,
                "map_at_10": 0.17498,
                "map_at_25": 0.19453,
                "map_at_50": 0.20294,
                "map_at_100": 0.20784,
                "Recall_at_1": 0.08328,
                "Recall_at_5": 0.19782,
                "Recall_at_10": 0.31014,
                "Recall_at_25": 0.42584,
                "Recall_at_50": 0.534,
                "Recall_at_100": 0.65502,
                "precision_at_1": 0.18812,
                "precision_at_5": 0.14257,
                "precision_at_10": 0.1099,
                "precision_at_25": 0.0701,
                "precision_at_50": 0.04792,
                "precision_at_100": 0.03059,
                "mrr": 0.27718
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.07449,
                "ndcg_at_1": 0.07207,
                "ndcg_at_5": 0.06813,
                "ndcg_at_10": 0.07449,
                "ndcg_at_25": 0.08626,
                "ndcg_at_50": 0.10085,
                "ndcg_at_100": 0.11047,
                "map_at_1": 0.01051,
                "map_at_5": 0.03632,
                "map_at_10": 0.04796,
                "map_at_25": 0.05131,
                "map_at_50": 0.05369,
                "map_at_100": 0.0547,
                "Recall_at_1": 0.01051,
                "Recall_at_5": 0.05454,
                "Recall_at_10": 0.08655,
                "Recall_at_25": 0.11803,
                "Recall_at_50": 0.16693,
                "Recall_at_100": 0.20383,
                "precision_at_1": 0.07207,
                "precision_at_5": 0.06486,
                "precision_at_10": 0.05045,
                "precision_at_25": 0.02595,
                "precision_at_50": 0.01712,
                "precision_at_100": 0.01027,
                "mrr": 0.11313
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.1558,
                "ndcg_at_1": 0.12037,
                "ndcg_at_5": 0.12891,
                "ndcg_at_10": 0.1558,
                "ndcg_at_25": 0.19509,
                "ndcg_at_50": 0.22142,
                "ndcg_at_100": 0.25656,
                "map_at_1": 0.04147,
                "map_at_5": 0.08338,
                "map_at_10": 0.10179,
                "map_at_25": 0.11829,
                "map_at_50": 0.12454,
                "map_at_100": 0.13091,
                "Recall_at_1": 0.04147,
                "Recall_at_5": 0.12661,
                "Recall_at_10": 0.20543,
                "Recall_at_25": 0.32307,
                "Recall_at_50": 0.40798,
                "Recall_at_100": 0.5478,
                "precision_at_1": 0.12037,
                "precision_at_5": 0.08704,
                "precision_at_10": 0.075,
                "precision_at_25": 0.05074,
                "precision_at_50": 0.03611,
                "precision_at_100": 0.02593,
                "mrr": 0.20076
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.01481,
                "ndcg_at_1": 0.02679,
                "ndcg_at_5": 0.02011,
                "ndcg_at_10": 0.01481,
                "ndcg_at_25": 0.01324,
                "ndcg_at_50": 0.01723,
                "ndcg_at_100": 0.02295,
                "map_at_1": 0.00135,
                "map_at_5": 0.0032,
                "map_at_10": 0.00331,
                "map_at_25": 0.00362,
                "map_at_50": 0.00398,
                "map_at_100": 0.00432,
                "Recall_at_1": 0.00135,
                "Recall_at_5": 0.00507,
                "Recall_at_10": 0.0058,
                "Recall_at_25": 0.01043,
                "Recall_at_50": 0.01873,
                "Recall_at_100": 0.03085,
                "precision_at_1": 0.02679,
                "precision_at_5": 0.01786,
                "precision_at_10": 0.01071,
                "precision_at_25": 0.00857,
                "precision_at_50": 0.00768,
                "precision_at_100": 0.00652,
                "mrr": 0.05551
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.10128,
                "ndcg_at_1": 0.09231,
                "ndcg_at_5": 0.09778,
                "ndcg_at_10": 0.10128,
                "ndcg_at_25": 0.13144,
                "ndcg_at_50": 0.15753,
                "ndcg_at_100": 0.18175,
                "map_at_1": 0.03385,
                "map_at_5": 0.0741,
                "map_at_10": 0.07716,
                "map_at_25": 0.08486,
                "map_at_50": 0.08921,
                "map_at_100": 0.09167,
                "Recall_at_1": 0.03385,
                "Recall_at_5": 0.12103,
                "Recall_at_10": 0.12872,
                "Recall_at_25": 0.24154,
                "Recall_at_50": 0.36077,
                "Recall_at_100": 0.48872,
                "precision_at_1": 0.09231,
                "precision_at_5": 0.04923,
                "precision_at_10": 0.02769,
                "precision_at_25": 0.01785,
                "precision_at_50": 0.01262,
                "precision_at_100": 0.00862,
                "mrr": 0.13921
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23552,
                "ndcg_at_1": 0.18447,
                "ndcg_at_5": 0.20546,
                "ndcg_at_10": 0.23552,
                "ndcg_at_25": 0.27602,
                "ndcg_at_50": 0.29962,
                "ndcg_at_100": 0.32645,
                "map_at_1": 0.05303,
                "map_at_5": 0.13537,
                "map_at_10": 0.16143,
                "map_at_25": 0.17948,
                "map_at_50": 0.18628,
                "map_at_100": 0.19024,
                "Recall_at_1": 0.05303,
                "Recall_at_5": 0.20556,
                "Recall_at_10": 0.29298,
                "Recall_at_25": 0.41167,
                "Recall_at_50": 0.49,
                "Recall_at_100": 0.60618,
                "precision_at_1": 0.18447,
                "precision_at_5": 0.14951,
                "precision_at_10": 0.10971,
                "precision_at_25": 0.06214,
                "precision_at_50": 0.03786,
                "precision_at_100": 0.02272,
                "mrr": 0.30076
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15034,
                "ndcg_at_1": 0.12821,
                "ndcg_at_5": 0.13332,
                "ndcg_at_10": 0.15034,
                "ndcg_at_25": 0.19195,
                "ndcg_at_50": 0.2278,
                "ndcg_at_100": 0.24506,
                "map_at_1": 0.0434,
                "map_at_5": 0.08455,
                "map_at_10": 0.09794,
                "map_at_25": 0.11497,
                "map_at_50": 0.12426,
                "map_at_100": 0.12738,
                "Recall_at_1": 0.0434,
                "Recall_at_5": 0.11759,
                "Recall_at_10": 0.17524,
                "Recall_at_25": 0.29522,
                "Recall_at_50": 0.41908,
                "Recall_at_100": 0.47921,
                "precision_at_1": 0.12821,
                "precision_at_5": 0.09744,
                "precision_at_10": 0.0735,
                "precision_at_25": 0.05538,
                "precision_at_50": 0.04137,
                "precision_at_100": 0.02538,
                "mrr": 0.2073
            }
        ]
    },
    "task_name": "BrightRetrieval"
}