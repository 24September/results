{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21976,
                "ndcg_at_1": 0.41964,
                "ndcg_at_5": 0.26996,
                "ndcg_at_10": 0.21976,
                "ndcg_at_25": 0.18411,
                "ndcg_at_50": 0.21325,
                "ndcg_at_100": 0.26322,
                "map_at_1": 0.01924,
                "map_at_5": 0.03684,
                "map_at_10": 0.04507,
                "map_at_25": 0.05839,
                "map_at_50": 0.0662,
                "map_at_100": 0.07628,
                "Recall_at_1": 0.01924,
                "Recall_at_5": 0.05345,
                "Recall_at_10": 0.08235,
                "Recall_at_25": 0.15675,
                "Recall_at_50": 0.2212,
                "Recall_at_100": 0.32622,
                "precision_at_1": 0.41964,
                "precision_at_5": 0.23571,
                "precision_at_10": 0.17857,
                "precision_at_25": 0.1275,
                "precision_at_50": 0.09161,
                "precision_at_100": 0.06955,
                "mrr": 0.56457
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17306,
                "ndcg_at_1": 0.13861,
                "ndcg_at_5": 0.16896,
                "ndcg_at_10": 0.17306,
                "ndcg_at_25": 0.18861,
                "ndcg_at_50": 0.20992,
                "ndcg_at_100": 0.2267,
                "map_at_1": 0.06128,
                "map_at_5": 0.10621,
                "map_at_10": 0.11631,
                "map_at_25": 0.12465,
                "map_at_50": 0.12907,
                "map_at_100": 0.13141,
                "Recall_at_1": 0.06128,
                "Recall_at_5": 0.16451,
                "Recall_at_10": 0.21313,
                "Recall_at_25": 0.28018,
                "Recall_at_50": 0.34443,
                "Recall_at_100": 0.4103,
                "precision_at_1": 0.13861,
                "precision_at_5": 0.10495,
                "precision_at_10": 0.06832,
                "precision_at_25": 0.04079,
                "precision_at_50": 0.0299,
                "precision_at_100": 0.01881,
                "mrr": 0.22242
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18998,
                "ndcg_at_1": 0.17476,
                "ndcg_at_5": 0.18611,
                "ndcg_at_10": 0.18998,
                "ndcg_at_25": 0.22426,
                "ndcg_at_50": 0.25046,
                "ndcg_at_100": 0.26922,
                "map_at_1": 0.0648,
                "map_at_5": 0.10631,
                "map_at_10": 0.11694,
                "map_at_25": 0.13926,
                "map_at_50": 0.15241,
                "map_at_100": 0.16033,
                "Recall_at_1": 0.0648,
                "Recall_at_5": 0.14516,
                "Recall_at_10": 0.18315,
                "Recall_at_25": 0.31326,
                "Recall_at_50": 0.4264,
                "Recall_at_100": 0.4937,
                "precision_at_1": 0.17476,
                "precision_at_5": 0.11845,
                "precision_at_10": 0.09223,
                "precision_at_25": 0.07728,
                "precision_at_50": 0.05942,
                "precision_at_100": 0.03932,
                "mrr": 0.2538
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23345,
                "ndcg_at_1": 0.23902,
                "ndcg_at_5": 0.21486,
                "ndcg_at_10": 0.23345,
                "ndcg_at_25": 0.25436,
                "ndcg_at_50": 0.26263,
                "ndcg_at_100": 0.27354,
                "map_at_1": 0.13049,
                "map_at_5": 0.18728,
                "map_at_10": 0.19767,
                "map_at_25": 0.205,
                "map_at_50": 0.20629,
                "map_at_100": 0.20748,
                "Recall_at_1": 0.13049,
                "Recall_at_5": 0.21911,
                "Recall_at_10": 0.26167,
                "Recall_at_25": 0.33281,
                "Recall_at_50": 0.36887,
                "Recall_at_100": 0.4238,
                "precision_at_1": 0.23902,
                "precision_at_5": 0.09171,
                "precision_at_10": 0.05707,
                "precision_at_25": 0.02849,
                "precision_at_50": 0.01561,
                "precision_at_100": 0.00893,
                "mrr": 0.28012
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.29848,
                "ndcg_at_1": 0.28169,
                "ndcg_at_5": 0.27607,
                "ndcg_at_10": 0.29848,
                "ndcg_at_25": 0.33506,
                "ndcg_at_50": 0.35014,
                "ndcg_at_100": 0.36796,
                "map_at_1": 0.14437,
                "map_at_5": 0.22141,
                "map_at_10": 0.23318,
                "map_at_25": 0.24313,
                "map_at_50": 0.24649,
                "map_at_100": 0.24873,
                "Recall_at_1": 0.14437,
                "Recall_at_5": 0.30657,
                "Recall_at_10": 0.36338,
                "Recall_at_25": 0.50211,
                "Recall_at_50": 0.56303,
                "Recall_at_100": 0.65751,
                "precision_at_1": 0.28169,
                "precision_at_5": 0.12676,
                "precision_at_10": 0.07465,
                "precision_at_25": 0.03803,
                "precision_at_50": 0.02183,
                "precision_at_100": 0.01246,
                "mrr": 0.37664
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.32774,
                "ndcg_at_1": 0.2931,
                "ndcg_at_5": 0.30669,
                "ndcg_at_10": 0.32774,
                "ndcg_at_25": 0.35392,
                "ndcg_at_50": 0.37629,
                "ndcg_at_100": 0.40101,
                "map_at_1": 0.11557,
                "map_at_5": 0.22136,
                "map_at_10": 0.24497,
                "map_at_25": 0.25723,
                "map_at_50": 0.2633,
                "map_at_100": 0.26752,
                "Recall_at_1": 0.11557,
                "Recall_at_5": 0.31915,
                "Recall_at_10": 0.38767,
                "Recall_at_25": 0.46173,
                "Recall_at_50": 0.53304,
                "Recall_at_100": 0.61688,
                "precision_at_1": 0.2931,
                "precision_at_5": 0.18276,
                "precision_at_10": 0.12672,
                "precision_at_25": 0.06655,
                "precision_at_50": 0.04069,
                "precision_at_100": 0.02595,
                "mrr": 0.41769
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.11617,
                "ndcg_at_1": 0.09402,
                "ndcg_at_5": 0.10106,
                "ndcg_at_10": 0.11617,
                "ndcg_at_25": 0.14568,
                "ndcg_at_50": 0.17933,
                "ndcg_at_100": 0.2083,
                "map_at_1": 0.01724,
                "map_at_5": 0.0494,
                "map_at_10": 0.06248,
                "map_at_25": 0.07288,
                "map_at_50": 0.08037,
                "map_at_100": 0.08571,
                "Recall_at_1": 0.01724,
                "Recall_at_5": 0.09719,
                "Recall_at_10": 0.15123,
                "Recall_at_25": 0.2495,
                "Recall_at_50": 0.3628,
                "Recall_at_100": 0.46333,
                "precision_at_1": 0.09402,
                "precision_at_5": 0.07521,
                "precision_at_10": 0.05983,
                "precision_at_25": 0.04205,
                "precision_at_50": 0.03453,
                "precision_at_100": 0.02547,
                "mrr": 0.18098
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18043,
                "ndcg_at_1": 0.14815,
                "ndcg_at_5": 0.15619,
                "ndcg_at_10": 0.18043,
                "ndcg_at_25": 0.22666,
                "ndcg_at_50": 0.25564,
                "ndcg_at_100": 0.28292,
                "map_at_1": 0.06798,
                "map_at_5": 0.11355,
                "map_at_10": 0.12923,
                "map_at_25": 0.14483,
                "map_at_50": 0.15314,
                "map_at_100": 0.15787,
                "Recall_at_1": 0.06798,
                "Recall_at_5": 0.16461,
                "Recall_at_10": 0.23374,
                "Recall_at_25": 0.36354,
                "Recall_at_50": 0.45405,
                "Recall_at_100": 0.55827,
                "precision_at_1": 0.14815,
                "precision_at_5": 0.08704,
                "precision_at_10": 0.06759,
                "precision_at_25": 0.05148,
                "precision_at_50": 0.03704,
                "precision_at_100": 0.02491,
                "mrr": 0.23523
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.25043,
                "ndcg_at_1": 0.2233,
                "ndcg_at_5": 0.21612,
                "ndcg_at_10": 0.25043,
                "ndcg_at_25": 0.2884,
                "ndcg_at_50": 0.31431,
                "ndcg_at_100": 0.34317,
                "map_at_1": 0.08386,
                "map_at_5": 0.1521,
                "map_at_10": 0.17852,
                "map_at_25": 0.19684,
                "map_at_50": 0.20415,
                "map_at_100": 0.20797,
                "Recall_at_1": 0.08386,
                "Recall_at_5": 0.21341,
                "Recall_at_10": 0.30346,
                "Recall_at_25": 0.40339,
                "Recall_at_50": 0.48784,
                "Recall_at_100": 0.61337,
                "precision_at_1": 0.2233,
                "precision_at_5": 0.14369,
                "precision_at_10": 0.11068,
                "precision_at_25": 0.06252,
                "precision_at_50": 0.03903,
                "precision_at_100": 0.02379,
                "mrr": 0.31717
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19925,
                "ndcg_at_1": 0.15842,
                "ndcg_at_5": 0.17434,
                "ndcg_at_10": 0.19925,
                "ndcg_at_25": 0.22458,
                "ndcg_at_50": 0.25146,
                "ndcg_at_100": 0.2738,
                "map_at_1": 0.03742,
                "map_at_5": 0.09003,
                "map_at_10": 0.11886,
                "map_at_25": 0.14257,
                "map_at_50": 0.15111,
                "map_at_100": 0.15461,
                "Recall_at_1": 0.03742,
                "Recall_at_5": 0.17737,
                "Recall_at_10": 0.26869,
                "Recall_at_25": 0.36907,
                "Recall_at_50": 0.48822,
                "Recall_at_100": 0.59109,
                "precision_at_1": 0.15842,
                "precision_at_5": 0.12475,
                "precision_at_10": 0.10792,
                "precision_at_25": 0.07168,
                "precision_at_50": 0.04554,
                "precision_at_100": 0.02683,
                "mrr": 0.23193
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17409,
                "ndcg_at_1": 0.12308,
                "ndcg_at_5": 0.13826,
                "ndcg_at_10": 0.17409,
                "ndcg_at_25": 0.20691,
                "ndcg_at_50": 0.23481,
                "ndcg_at_100": 0.24408,
                "map_at_1": 0.06795,
                "map_at_5": 0.1087,
                "map_at_10": 0.12574,
                "map_at_25": 0.13366,
                "map_at_50": 0.13865,
                "map_at_100": 0.14003,
                "Recall_at_1": 0.06795,
                "Recall_at_5": 0.1641,
                "Recall_at_10": 0.26154,
                "Recall_at_25": 0.38205,
                "Recall_at_50": 0.50769,
                "Recall_at_100": 0.54795,
                "precision_at_1": 0.12308,
                "precision_at_5": 0.06769,
                "precision_at_10": 0.04923,
                "precision_at_25": 0.02769,
                "precision_at_50": 0.01846,
                "precision_at_100": 0.01046,
                "mrr": 0.19475
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.08908,
                "ndcg_at_1": 0.11712,
                "ndcg_at_5": 0.0845,
                "ndcg_at_10": 0.08908,
                "ndcg_at_25": 0.10862,
                "ndcg_at_50": 0.12177,
                "ndcg_at_100": 0.14555,
                "map_at_1": 0.02365,
                "map_at_5": 0.05307,
                "map_at_10": 0.0621,
                "map_at_25": 0.06687,
                "map_at_50": 0.0692,
                "map_at_100": 0.07207,
                "Recall_at_1": 0.02365,
                "Recall_at_5": 0.06848,
                "Recall_at_10": 0.09422,
                "Recall_at_25": 0.14565,
                "Recall_at_50": 0.18533,
                "Recall_at_100": 0.27343,
                "precision_at_1": 0.11712,
                "precision_at_5": 0.06486,
                "precision_at_10": 0.04595,
                "precision_at_25": 0.02775,
                "precision_at_50": 0.0182,
                "precision_at_100": 0.01342,
                "mrr": 0.14836
            }
        ]
    },
    "task_name": "BrightRetrieval"
}