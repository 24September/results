{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21823,
                "ndcg_at_1": 0.18812,
                "ndcg_at_5": 0.20228,
                "ndcg_at_10": 0.21823,
                "ndcg_at_25": 0.24696,
                "ndcg_at_50": 0.26808,
                "ndcg_at_100": 0.29599,
                "map_at_1": 0.05814,
                "map_at_5": 0.12046,
                "map_at_10": 0.14212,
                "map_at_25": 0.16405,
                "map_at_50": 0.16957,
                "map_at_100": 0.17443,
                "Recall_at_1": 0.05814,
                "Recall_at_5": 0.16749,
                "Recall_at_10": 0.25134,
                "Recall_at_25": 0.3758,
                "Recall_at_50": 0.4573,
                "Recall_at_100": 0.57679,
                "precision_at_1": 0.18812,
                "precision_at_5": 0.13663,
                "precision_at_10": 0.10198,
                "precision_at_25": 0.06693,
                "precision_at_50": 0.04436,
                "precision_at_100": 0.02871,
                "mrr": 0.27665
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.20185,
                "ndcg_at_1": 0.15534,
                "ndcg_at_5": 0.19145,
                "ndcg_at_10": 0.20185,
                "ndcg_at_25": 0.22909,
                "ndcg_at_50": 0.24993,
                "ndcg_at_100": 0.26924,
                "map_at_1": 0.03475,
                "map_at_5": 0.10182,
                "map_at_10": 0.11747,
                "map_at_25": 0.13623,
                "map_at_50": 0.14624,
                "map_at_100": 0.15216,
                "Recall_at_1": 0.03475,
                "Recall_at_5": 0.17231,
                "Recall_at_10": 0.22402,
                "Recall_at_25": 0.34823,
                "Recall_at_50": 0.44208,
                "Recall_at_100": 0.51574,
                "precision_at_1": 0.15534,
                "precision_at_5": 0.12816,
                "precision_at_10": 0.10388,
                "precision_at_25": 0.07534,
                "precision_at_50": 0.0532,
                "precision_at_100": 0.03466,
                "mrr": 0.25056
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16211,
                "ndcg_at_1": 0.18812,
                "ndcg_at_5": 0.1599,
                "ndcg_at_10": 0.16211,
                "ndcg_at_25": 0.18741,
                "ndcg_at_50": 0.21416,
                "ndcg_at_100": 0.22839,
                "map_at_1": 0.06417,
                "map_at_5": 0.10481,
                "map_at_10": 0.11268,
                "map_at_25": 0.12302,
                "map_at_50": 0.12867,
                "map_at_100": 0.13067,
                "Recall_at_1": 0.06417,
                "Recall_at_5": 0.14288,
                "Recall_at_10": 0.17651,
                "Recall_at_25": 0.269,
                "Recall_at_50": 0.3771,
                "Recall_at_100": 0.43352,
                "precision_at_1": 0.18812,
                "precision_at_5": 0.09505,
                "precision_at_10": 0.06535,
                "precision_at_25": 0.04356,
                "precision_at_50": 0.0295,
                "precision_at_100": 0.01802,
                "mrr": 0.24142
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18978,
                "ndcg_at_1": 0.16505,
                "ndcg_at_5": 0.17454,
                "ndcg_at_10": 0.18978,
                "ndcg_at_25": 0.22773,
                "ndcg_at_50": 0.25247,
                "ndcg_at_100": 0.28335,
                "map_at_1": 0.0434,
                "map_at_5": 0.10616,
                "map_at_10": 0.12105,
                "map_at_25": 0.1367,
                "map_at_50": 0.14193,
                "map_at_100": 0.14624,
                "Recall_at_1": 0.0434,
                "Recall_at_5": 0.18077,
                "Recall_at_10": 0.23136,
                "Recall_at_25": 0.33892,
                "Recall_at_50": 0.42433,
                "Recall_at_100": 0.55949,
                "precision_at_1": 0.16505,
                "precision_at_5": 0.12621,
                "precision_at_10": 0.08641,
                "precision_at_25": 0.05165,
                "precision_at_50": 0.03282,
                "precision_at_100": 0.02107,
                "mrr": 0.27194
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16465,
                "ndcg_at_1": 0.15385,
                "ndcg_at_5": 0.14298,
                "ndcg_at_10": 0.16465,
                "ndcg_at_25": 0.1897,
                "ndcg_at_50": 0.21659,
                "ndcg_at_100": 0.24688,
                "map_at_1": 0.03844,
                "map_at_5": 0.08066,
                "map_at_10": 0.09662,
                "map_at_25": 0.10725,
                "map_at_50": 0.11405,
                "map_at_100": 0.1191,
                "Recall_at_1": 0.03844,
                "Recall_at_5": 0.14358,
                "Recall_at_10": 0.21203,
                "Recall_at_25": 0.28273,
                "Recall_at_50": 0.36804,
                "Recall_at_100": 0.48952,
                "precision_at_1": 0.15385,
                "precision_at_5": 0.09744,
                "precision_at_10": 0.07778,
                "precision_at_25": 0.05368,
                "precision_at_50": 0.03966,
                "precision_at_100": 0.02667,
                "mrr": 0.24286
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.06038,
                "ndcg_at_1": 0.03077,
                "ndcg_at_5": 0.04492,
                "ndcg_at_10": 0.06038,
                "ndcg_at_25": 0.07583,
                "ndcg_at_50": 0.09984,
                "ndcg_at_100": 0.11176,
                "map_at_1": 0.01282,
                "map_at_5": 0.03846,
                "map_at_10": 0.04515,
                "map_at_25": 0.04835,
                "map_at_50": 0.0522,
                "map_at_100": 0.05341,
                "Recall_at_1": 0.01282,
                "Recall_at_5": 0.05385,
                "Recall_at_10": 0.1,
                "Recall_at_25": 0.15897,
                "Recall_at_50": 0.27051,
                "Recall_at_100": 0.33333,
                "precision_at_1": 0.03077,
                "precision_at_5": 0.02462,
                "precision_at_10": 0.01692,
                "precision_at_25": 0.01046,
                "precision_at_50": 0.00862,
                "precision_at_100": 0.00538,
                "mrr": 0.06393
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.01773,
                "ndcg_at_1": 0.01786,
                "ndcg_at_5": 0.01642,
                "ndcg_at_10": 0.01773,
                "ndcg_at_25": 0.01903,
                "ndcg_at_50": 0.02745,
                "ndcg_at_100": 0.03984,
                "map_at_1": 0.0018,
                "map_at_5": 0.00295,
                "map_at_10": 0.00355,
                "map_at_25": 0.00438,
                "map_at_50": 0.00531,
                "map_at_100": 0.00614,
                "Recall_at_1": 0.0018,
                "Recall_at_5": 0.00494,
                "Recall_at_10": 0.00891,
                "Recall_at_25": 0.01887,
                "Recall_at_50": 0.03612,
                "Recall_at_100": 0.06218,
                "precision_at_1": 0.01786,
                "precision_at_5": 0.01607,
                "precision_at_10": 0.01786,
                "precision_at_25": 0.015,
                "precision_at_50": 0.01393,
                "precision_at_100": 0.01295,
                "mrr": 0.06386
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17692,
                "ndcg_at_1": 0.12963,
                "ndcg_at_5": 0.15201,
                "ndcg_at_10": 0.17692,
                "ndcg_at_25": 0.22053,
                "ndcg_at_50": 0.25283,
                "ndcg_at_100": 0.28336,
                "map_at_1": 0.04498,
                "map_at_5": 0.09571,
                "map_at_10": 0.11353,
                "map_at_25": 0.13095,
                "map_at_50": 0.14093,
                "map_at_100": 0.14616,
                "Recall_at_1": 0.04498,
                "Recall_at_5": 0.15885,
                "Recall_at_10": 0.23436,
                "Recall_at_25": 0.36151,
                "Recall_at_50": 0.45659,
                "Recall_at_100": 0.5814,
                "precision_at_1": 0.12963,
                "precision_at_5": 0.11111,
                "precision_at_10": 0.08519,
                "precision_at_25": 0.05852,
                "precision_at_50": 0.04315,
                "precision_at_100": 0.02787,
                "mrr": 0.22846
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.06462,
                "ndcg_at_1": 0.07207,
                "ndcg_at_5": 0.06166,
                "ndcg_at_10": 0.06462,
                "ndcg_at_25": 0.07919,
                "ndcg_at_50": 0.08958,
                "ndcg_at_100": 0.10645,
                "map_at_1": 0.01341,
                "map_at_5": 0.03251,
                "map_at_10": 0.03859,
                "map_at_25": 0.04331,
                "map_at_50": 0.0456,
                "map_at_100": 0.04742,
                "Recall_at_1": 0.01341,
                "Recall_at_5": 0.0488,
                "Recall_at_10": 0.07132,
                "Recall_at_25": 0.10913,
                "Recall_at_50": 0.13728,
                "Recall_at_100": 0.20174,
                "precision_at_1": 0.07207,
                "precision_at_5": 0.04865,
                "precision_at_10": 0.03423,
                "precision_at_25": 0.02054,
                "precision_at_50": 0.01423,
                "precision_at_100": 0.01009,
                "mrr": 0.11634
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15072,
                "ndcg_at_1": 0.16585,
                "ndcg_at_5": 0.14465,
                "ndcg_at_10": 0.15072,
                "ndcg_at_25": 0.16037,
                "ndcg_at_50": 0.17086,
                "ndcg_at_100": 0.18269,
                "map_at_1": 0.10569,
                "map_at_5": 0.12829,
                "map_at_10": 0.13137,
                "map_at_25": 0.13465,
                "map_at_50": 0.13615,
                "map_at_100": 0.13741,
                "Recall_at_1": 0.10569,
                "Recall_at_5": 0.14228,
                "Recall_at_10": 0.15447,
                "Recall_at_25": 0.18769,
                "Recall_at_50": 0.23606,
                "Recall_at_100": 0.29354,
                "precision_at_1": 0.16585,
                "precision_at_5": 0.05171,
                "precision_at_10": 0.03024,
                "precision_at_25": 0.01463,
                "precision_at_50": 0.00888,
                "precision_at_100": 0.00571,
                "mrr": 0.19111
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26776,
                "ndcg_at_1": 0.28169,
                "ndcg_at_5": 0.24429,
                "ndcg_at_10": 0.26776,
                "ndcg_at_25": 0.29118,
                "ndcg_at_50": 0.30554,
                "ndcg_at_100": 0.31939,
                "map_at_1": 0.15293,
                "map_at_5": 0.20698,
                "map_at_10": 0.21776,
                "map_at_25": 0.22438,
                "map_at_50": 0.22678,
                "map_at_100": 0.22818,
                "Recall_at_1": 0.15293,
                "Recall_at_5": 0.24871,
                "Recall_at_10": 0.31056,
                "Recall_at_25": 0.39507,
                "Recall_at_50": 0.46315,
                "Recall_at_100": 0.53697,
                "precision_at_1": 0.28169,
                "precision_at_5": 0.10704,
                "precision_at_10": 0.06479,
                "precision_at_25": 0.03099,
                "precision_at_50": 0.01746,
                "precision_at_100": 0.01,
                "mrr": 0.34032
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27452,
                "ndcg_at_1": 0.28448,
                "ndcg_at_5": 0.25672,
                "ndcg_at_10": 0.27452,
                "ndcg_at_25": 0.30337,
                "ndcg_at_50": 0.32674,
                "ndcg_at_100": 0.35177,
                "map_at_1": 0.12962,
                "map_at_5": 0.19498,
                "map_at_10": 0.21287,
                "map_at_25": 0.22454,
                "map_at_50": 0.22961,
                "map_at_100": 0.23404,
                "Recall_at_1": 0.12962,
                "Recall_at_5": 0.24012,
                "Recall_at_10": 0.29579,
                "Recall_at_25": 0.37788,
                "Recall_at_50": 0.45206,
                "Recall_at_100": 0.54211,
                "precision_at_1": 0.28448,
                "precision_at_5": 0.1431,
                "precision_at_10": 0.10345,
                "precision_at_25": 0.05724,
                "precision_at_50": 0.0369,
                "precision_at_100": 0.02379,
                "mrr": 0.37019
            }
        ]
    },
    "task_name": "BrightRetrieval"
}