{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.1985,
                "ndcg_at_1": 0.17094,
                "ndcg_at_5": 0.18638,
                "ndcg_at_10": 0.1985,
                "ndcg_at_25": 0.2448,
                "ndcg_at_50": 0.27216,
                "ndcg_at_100": 0.31065,
                "map_at_1": 0.0485,
                "map_at_5": 0.11095,
                "map_at_10": 0.12849,
                "map_at_25": 0.14803,
                "map_at_50": 0.15634,
                "map_at_100": 0.16456,
                "Recall_at_1": 0.0485,
                "Recall_at_5": 0.16386,
                "Recall_at_10": 0.22449,
                "Recall_at_25": 0.37581,
                "Recall_at_50": 0.45661,
                "Recall_at_100": 0.60402,
                "precision_at_1": 0.17094,
                "precision_at_5": 0.13846,
                "precision_at_10": 0.10085,
                "precision_at_25": 0.06906,
                "precision_at_50": 0.04872,
                "precision_at_100": 0.03436,
                "mrr": 0.27387
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.36224,
                "ndcg_at_1": 0.35345,
                "ndcg_at_5": 0.34335,
                "ndcg_at_10": 0.36224,
                "ndcg_at_25": 0.39493,
                "ndcg_at_50": 0.41562,
                "ndcg_at_100": 0.44237,
                "map_at_1": 0.12721,
                "map_at_5": 0.25364,
                "map_at_10": 0.28134,
                "map_at_25": 0.29655,
                "map_at_50": 0.30304,
                "map_at_100": 0.30742,
                "Recall_at_1": 0.12721,
                "Recall_at_5": 0.33101,
                "Recall_at_10": 0.40568,
                "Recall_at_25": 0.49541,
                "Recall_at_50": 0.55413,
                "Recall_at_100": 0.65965,
                "precision_at_1": 0.35345,
                "precision_at_5": 0.21207,
                "precision_at_10": 0.14138,
                "precision_at_25": 0.07759,
                "precision_at_50": 0.04724,
                "precision_at_100": 0.02905,
                "mrr": 0.46553
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.25462,
                "ndcg_at_1": 0.23944,
                "ndcg_at_5": 0.22637,
                "ndcg_at_10": 0.25462,
                "ndcg_at_25": 0.28942,
                "ndcg_at_50": 0.30883,
                "ndcg_at_100": 0.32346,
                "map_at_1": 0.13239,
                "map_at_5": 0.17964,
                "map_at_10": 0.19313,
                "map_at_25": 0.20446,
                "map_at_50": 0.20767,
                "map_at_100": 0.20925,
                "Recall_at_1": 0.13239,
                "Recall_at_5": 0.2473,
                "Recall_at_10": 0.32077,
                "Recall_at_25": 0.44636,
                "Recall_at_50": 0.5338,
                "Recall_at_100": 0.61068,
                "precision_at_1": 0.23944,
                "precision_at_5": 0.09859,
                "precision_at_10": 0.06268,
                "precision_at_25": 0.03324,
                "precision_at_50": 0.01958,
                "precision_at_100": 0.0112,
                "mrr": 0.32558
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26966,
                "ndcg_at_1": 0.27317,
                "ndcg_at_5": 0.25336,
                "ndcg_at_10": 0.26966,
                "ndcg_at_25": 0.28949,
                "ndcg_at_50": 0.29996,
                "ndcg_at_100": 0.30977,
                "map_at_1": 0.15732,
                "map_at_5": 0.22261,
                "map_at_10": 0.2316,
                "map_at_25": 0.23779,
                "map_at_50": 0.23961,
                "map_at_100": 0.24067,
                "Recall_at_1": 0.15732,
                "Recall_at_5": 0.26005,
                "Recall_at_10": 0.30045,
                "Recall_at_25": 0.36875,
                "Recall_at_50": 0.41538,
                "Recall_at_100": 0.46271,
                "precision_at_1": 0.27317,
                "precision_at_5": 0.10439,
                "precision_at_10": 0.06195,
                "precision_at_25": 0.03005,
                "precision_at_50": 0.01678,
                "precision_at_100": 0.00961,
                "mrr": 0.32366
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17716,
                "ndcg_at_1": 0.17476,
                "ndcg_at_5": 0.16928,
                "ndcg_at_10": 0.17716,
                "ndcg_at_25": 0.21137,
                "ndcg_at_50": 0.23458,
                "ndcg_at_100": 0.26098,
                "map_at_1": 0.05662,
                "map_at_5": 0.10109,
                "map_at_10": 0.11267,
                "map_at_25": 0.13145,
                "map_at_50": 0.14327,
                "map_at_100": 0.15049,
                "Recall_at_1": 0.05662,
                "Recall_at_5": 0.13953,
                "Recall_at_10": 0.18495,
                "Recall_at_25": 0.31138,
                "Recall_at_50": 0.39798,
                "Recall_at_100": 0.49958,
                "precision_at_1": 0.17476,
                "precision_at_5": 0.10874,
                "precision_at_10": 0.08155,
                "precision_at_25": 0.06602,
                "precision_at_50": 0.05223,
                "precision_at_100": 0.03631,
                "mrr": 0.23629
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.13472,
                "ndcg_at_1": 0.12871,
                "ndcg_at_5": 0.12748,
                "ndcg_at_10": 0.13472,
                "ndcg_at_25": 0.16012,
                "ndcg_at_50": 0.1782,
                "ndcg_at_100": 0.19696,
                "map_at_1": 0.05029,
                "map_at_5": 0.07644,
                "map_at_10": 0.08754,
                "map_at_25": 0.09852,
                "map_at_50": 0.10236,
                "map_at_100": 0.10505,
                "Recall_at_1": 0.05029,
                "Recall_at_5": 0.09958,
                "Recall_at_10": 0.14453,
                "Recall_at_25": 0.24435,
                "Recall_at_50": 0.31044,
                "Recall_at_100": 0.385,
                "precision_at_1": 0.12871,
                "precision_at_5": 0.07723,
                "precision_at_10": 0.05842,
                "precision_at_25": 0.04,
                "precision_at_50": 0.02634,
                "precision_at_100": 0.01693,
                "mrr": 0.20298
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.0979,
                "ndcg_at_1": 0.08929,
                "ndcg_at_5": 0.09972,
                "ndcg_at_10": 0.0979,
                "ndcg_at_25": 0.10104,
                "ndcg_at_50": 0.13717,
                "ndcg_at_100": 0.18339,
                "map_at_1": 0.00429,
                "map_at_5": 0.01221,
                "map_at_10": 0.01766,
                "map_at_25": 0.02605,
                "map_at_50": 0.03271,
                "map_at_100": 0.04039,
                "Recall_at_1": 0.00429,
                "Recall_at_5": 0.02365,
                "Recall_at_10": 0.04638,
                "Recall_at_25": 0.10117,
                "Recall_at_50": 0.17967,
                "Recall_at_100": 0.27714,
                "precision_at_1": 0.08929,
                "precision_at_5": 0.1,
                "precision_at_10": 0.09732,
                "precision_at_25": 0.08714,
                "precision_at_50": 0.07232,
                "precision_at_100": 0.05839,
                "mrr": 0.24012
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.14358,
                "ndcg_at_1": 0.18018,
                "ndcg_at_5": 0.14216,
                "ndcg_at_10": 0.14358,
                "ndcg_at_25": 0.17543,
                "ndcg_at_50": 0.19582,
                "ndcg_at_100": 0.21979,
                "map_at_1": 0.03899,
                "map_at_5": 0.08332,
                "map_at_10": 0.09331,
                "map_at_25": 0.10384,
                "map_at_50": 0.10768,
                "map_at_100": 0.11099,
                "Recall_at_1": 0.03899,
                "Recall_at_5": 0.11165,
                "Recall_at_10": 0.14768,
                "Recall_at_25": 0.23096,
                "Recall_at_50": 0.29955,
                "Recall_at_100": 0.38846,
                "precision_at_1": 0.18018,
                "precision_at_5": 0.10991,
                "precision_at_10": 0.07117,
                "precision_at_25": 0.04396,
                "precision_at_50": 0.02775,
                "precision_at_100": 0.01847,
                "mrr": 0.26286
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.24615,
                "ndcg_at_1": 0.21782,
                "ndcg_at_5": 0.21756,
                "ndcg_at_10": 0.24615,
                "ndcg_at_25": 0.27116,
                "ndcg_at_50": 0.29095,
                "ndcg_at_100": 0.31022,
                "map_at_1": 0.09625,
                "map_at_5": 0.13742,
                "map_at_10": 0.16603,
                "map_at_25": 0.18885,
                "map_at_50": 0.19492,
                "map_at_100": 0.19847,
                "Recall_at_1": 0.09625,
                "Recall_at_5": 0.18183,
                "Recall_at_10": 0.29486,
                "Recall_at_25": 0.40386,
                "Recall_at_50": 0.49155,
                "Recall_at_100": 0.56043,
                "precision_at_1": 0.21782,
                "precision_at_5": 0.13069,
                "precision_at_10": 0.11188,
                "precision_at_25": 0.07089,
                "precision_at_50": 0.04376,
                "precision_at_100": 0.02752,
                "mrr": 0.29782
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26658,
                "ndcg_at_1": 0.15385,
                "ndcg_at_5": 0.24535,
                "ndcg_at_10": 0.26658,
                "ndcg_at_25": 0.30136,
                "ndcg_at_50": 0.32057,
                "ndcg_at_100": 0.33341,
                "map_at_1": 0.08462,
                "map_at_5": 0.20402,
                "map_at_10": 0.21451,
                "map_at_25": 0.22405,
                "map_at_50": 0.22794,
                "map_at_100": 0.22897,
                "Recall_at_1": 0.08462,
                "Recall_at_5": 0.31026,
                "Recall_at_10": 0.36667,
                "Recall_at_25": 0.49872,
                "Recall_at_50": 0.57949,
                "Recall_at_100": 0.64538,
                "precision_at_1": 0.15385,
                "precision_at_5": 0.11385,
                "precision_at_10": 0.06769,
                "precision_at_25": 0.03508,
                "precision_at_50": 0.02092,
                "precision_at_100": 0.01185,
                "mrr": 0.26885
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.30924,
                "ndcg_at_1": 0.27184,
                "ndcg_at_5": 0.26684,
                "ndcg_at_10": 0.30924,
                "ndcg_at_25": 0.33967,
                "ndcg_at_50": 0.36266,
                "ndcg_at_100": 0.39225,
                "map_at_1": 0.08264,
                "map_at_5": 0.18651,
                "map_at_10": 0.22026,
                "map_at_25": 0.23344,
                "map_at_50": 0.23902,
                "map_at_100": 0.24379,
                "Recall_at_1": 0.08264,
                "Recall_at_5": 0.25776,
                "Recall_at_10": 0.38186,
                "Recall_at_25": 0.46981,
                "Recall_at_50": 0.55373,
                "Recall_at_100": 0.67637,
                "precision_at_1": 0.27184,
                "precision_at_5": 0.18058,
                "precision_at_10": 0.13495,
                "precision_at_25": 0.06757,
                "precision_at_50": 0.03961,
                "precision_at_100": 0.02437,
                "mrr": 0.38764
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.14931,
                "ndcg_at_1": 0.12963,
                "ndcg_at_5": 0.13472,
                "ndcg_at_10": 0.14931,
                "ndcg_at_25": 0.17234,
                "ndcg_at_50": 0.19315,
                "ndcg_at_100": 0.21747,
                "map_at_1": 0.059,
                "map_at_5": 0.09137,
                "map_at_10": 0.10397,
                "map_at_25": 0.11671,
                "map_at_50": 0.12223,
                "map_at_100": 0.12573,
                "Recall_at_1": 0.059,
                "Recall_at_5": 0.11778,
                "Recall_at_10": 0.17409,
                "Recall_at_25": 0.23787,
                "Recall_at_50": 0.3117,
                "Recall_at_100": 0.41589,
                "precision_at_1": 0.12963,
                "precision_at_5": 0.07963,
                "precision_at_10": 0.06111,
                "precision_at_25": 0.04296,
                "precision_at_50": 0.02815,
                "precision_at_100": 0.01852,
                "mrr": 0.20343
            }
        ]
    },
    "task_name": "BrightRetrieval"
}