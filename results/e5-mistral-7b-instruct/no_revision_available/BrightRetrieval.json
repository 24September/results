{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18515,
                "ndcg_at_1": 0.13889,
                "ndcg_at_5": 0.17282,
                "ndcg_at_10": 0.18515,
                "ndcg_at_25": 0.21408,
                "ndcg_at_50": 0.24193,
                "ndcg_at_100": 0.2687,
                "map_at_1": 0.07407,
                "map_at_5": 0.12024,
                "map_at_10": 0.13279,
                "map_at_25": 0.14628,
                "map_at_50": 0.15333,
                "map_at_100": 0.15799,
                "Recall_at_1": 0.07407,
                "Recall_at_5": 0.18398,
                "Recall_at_10": 0.22954,
                "Recall_at_25": 0.31211,
                "Recall_at_50": 0.40215,
                "Recall_at_100": 0.50461,
                "precision_at_1": 0.13889,
                "precision_at_5": 0.1,
                "precision_at_10": 0.06852,
                "precision_at_25": 0.04444,
                "precision_at_50": 0.03241,
                "precision_at_100": 0.02222,
                "mrr": 0.23254
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15487,
                "ndcg_at_1": 0.1165,
                "ndcg_at_5": 0.14359,
                "ndcg_at_10": 0.15487,
                "ndcg_at_25": 0.18133,
                "ndcg_at_50": 0.19772,
                "ndcg_at_100": 0.2164,
                "map_at_1": 0.02827,
                "map_at_5": 0.06649,
                "map_at_10": 0.08017,
                "map_at_25": 0.09795,
                "map_at_50": 0.10828,
                "map_at_100": 0.11456,
                "Recall_at_1": 0.02827,
                "Recall_at_5": 0.11833,
                "Recall_at_10": 0.18364,
                "Recall_at_25": 0.29208,
                "Recall_at_50": 0.36203,
                "Recall_at_100": 0.43734,
                "precision_at_1": 0.1165,
                "precision_at_5": 0.10097,
                "precision_at_10": 0.08058,
                "precision_at_25": 0.06602,
                "precision_at_50": 0.0501,
                "precision_at_100": 0.03359,
                "mrr": 0.19485
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23777,
                "ndcg_at_1": 0.16923,
                "ndcg_at_5": 0.21052,
                "ndcg_at_10": 0.23777,
                "ndcg_at_25": 0.26221,
                "ndcg_at_50": 0.28107,
                "ndcg_at_100": 0.28816,
                "map_at_1": 0.09026,
                "map_at_5": 0.16303,
                "map_at_10": 0.17663,
                "map_at_25": 0.1825,
                "map_at_50": 0.18649,
                "map_at_100": 0.18722,
                "Recall_at_1": 0.09026,
                "Recall_at_5": 0.27487,
                "Recall_at_10": 0.34795,
                "Recall_at_25": 0.44154,
                "Recall_at_50": 0.52231,
                "Recall_at_100": 0.55821,
                "precision_at_1": 0.16923,
                "precision_at_5": 0.10154,
                "precision_at_10": 0.06308,
                "precision_at_25": 0.03077,
                "precision_at_50": 0.01846,
                "precision_at_100": 0.01,
                "mrr": 0.25753
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.07097,
                "ndcg_at_1": 0.05405,
                "ndcg_at_5": 0.06465,
                "ndcg_at_10": 0.07097,
                "ndcg_at_25": 0.08616,
                "ndcg_at_50": 0.09886,
                "ndcg_at_100": 0.11706,
                "map_at_1": 0.01437,
                "map_at_5": 0.03333,
                "map_at_10": 0.04096,
                "map_at_25": 0.04779,
                "map_at_50": 0.05016,
                "map_at_100": 0.0521,
                "Recall_at_1": 0.01437,
                "Recall_at_5": 0.05454,
                "Recall_at_10": 0.08231,
                "Recall_at_25": 0.11883,
                "Recall_at_50": 0.15755,
                "Recall_at_100": 0.22769,
                "precision_at_1": 0.05405,
                "precision_at_5": 0.05766,
                "precision_at_10": 0.04234,
                "precision_at_25": 0.0245,
                "precision_at_50": 0.0164,
                "precision_at_100": 0.01144,
                "mrr": 0.1158
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23942,
                "ndcg_at_1": 0.23902,
                "ndcg_at_5": 0.22779,
                "ndcg_at_10": 0.23942,
                "ndcg_at_25": 0.25462,
                "ndcg_at_50": 0.26448,
                "ndcg_at_100": 0.27404,
                "map_at_1": 0.13281,
                "map_at_5": 0.19858,
                "map_at_10": 0.20445,
                "map_at_25": 0.20964,
                "map_at_50": 0.21138,
                "map_at_100": 0.21232,
                "Recall_at_1": 0.13281,
                "Recall_at_5": 0.24216,
                "Recall_at_10": 0.27184,
                "Recall_at_25": 0.32062,
                "Recall_at_50": 0.36051,
                "Recall_at_100": 0.40951,
                "precision_at_1": 0.23902,
                "precision_at_5": 0.09951,
                "precision_at_10": 0.05659,
                "precision_at_25": 0.02712,
                "precision_at_50": 0.01551,
                "precision_at_100": 0.00873,
                "mrr": 0.28169
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.09826,
                "ndcg_at_1": 0.07692,
                "ndcg_at_5": 0.0863,
                "ndcg_at_10": 0.09826,
                "ndcg_at_25": 0.13243,
                "ndcg_at_50": 0.15987,
                "ndcg_at_100": 0.18574,
                "map_at_1": 0.02341,
                "map_at_5": 0.05186,
                "map_at_10": 0.06058,
                "map_at_25": 0.07331,
                "map_at_50": 0.07947,
                "map_at_100": 0.08342,
                "Recall_at_1": 0.02341,
                "Recall_at_5": 0.08512,
                "Recall_at_10": 0.11927,
                "Recall_at_25": 0.21981,
                "Recall_at_50": 0.31524,
                "Recall_at_100": 0.41511,
                "precision_at_1": 0.07692,
                "precision_at_5": 0.05812,
                "precision_at_10": 0.04615,
                "precision_at_25": 0.03658,
                "precision_at_50": 0.02923,
                "precision_at_100": 0.02051,
                "mrr": 0.14998
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15789,
                "ndcg_at_1": 0.14851,
                "ndcg_at_5": 0.13682,
                "ndcg_at_10": 0.15789,
                "ndcg_at_25": 0.20025,
                "ndcg_at_50": 0.22952,
                "ndcg_at_100": 0.25405,
                "map_at_1": 0.031,
                "map_at_5": 0.07455,
                "map_at_10": 0.0962,
                "map_at_25": 0.12027,
                "map_at_50": 0.13011,
                "map_at_100": 0.13333,
                "Recall_at_1": 0.031,
                "Recall_at_5": 0.11488,
                "Recall_at_10": 0.18313,
                "Recall_at_25": 0.34594,
                "Recall_at_50": 0.4567,
                "Recall_at_100": 0.57554,
                "precision_at_1": 0.14851,
                "precision_at_5": 0.09505,
                "precision_at_10": 0.08614,
                "precision_at_25": 0.06297,
                "precision_at_50": 0.04337,
                "precision_at_100": 0.02614,
                "mrr": 0.21591
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.04811,
                "ndcg_at_1": 0.04464,
                "ndcg_at_5": 0.04608,
                "ndcg_at_10": 0.04811,
                "ndcg_at_25": 0.0642,
                "ndcg_at_50": 0.10182,
                "ndcg_at_100": 0.15041,
                "map_at_1": 0.00285,
                "map_at_5": 0.00638,
                "map_at_10": 0.00836,
                "map_at_25": 0.01311,
                "map_at_50": 0.01917,
                "map_at_100": 0.02627,
                "Recall_at_1": 0.00285,
                "Recall_at_5": 0.01223,
                "Recall_at_10": 0.02433,
                "Recall_at_25": 0.06775,
                "Recall_at_50": 0.1378,
                "Recall_at_100": 0.23835,
                "precision_at_1": 0.04464,
                "precision_at_5": 0.04643,
                "precision_at_10": 0.04911,
                "precision_at_25": 0.06107,
                "precision_at_50": 0.06304,
                "precision_at_100": 0.055,
                "mrr": 0.1507
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.28717,
                "ndcg_at_1": 0.26761,
                "ndcg_at_5": 0.26602,
                "ndcg_at_10": 0.28717,
                "ndcg_at_25": 0.30895,
                "ndcg_at_50": 0.33772,
                "ndcg_at_100": 0.35653,
                "map_at_1": 0.14707,
                "map_at_5": 0.21922,
                "map_at_10": 0.22967,
                "map_at_25": 0.23654,
                "map_at_50": 0.24131,
                "map_at_100": 0.24366,
                "Recall_at_1": 0.14707,
                "Recall_at_5": 0.29202,
                "Recall_at_10": 0.34613,
                "Recall_at_25": 0.425,
                "Recall_at_50": 0.55939,
                "Recall_at_100": 0.65023,
                "precision_at_1": 0.26761,
                "precision_at_5": 0.11549,
                "precision_at_10": 0.06901,
                "precision_at_25": 0.03296,
                "precision_at_50": 0.02042,
                "precision_at_100": 0.01232,
                "mrr": 0.35243
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18837,
                "ndcg_at_1": 0.18447,
                "ndcg_at_5": 0.16297,
                "ndcg_at_10": 0.18837,
                "ndcg_at_25": 0.22736,
                "ndcg_at_50": 0.26045,
                "ndcg_at_100": 0.28991,
                "map_at_1": 0.06021,
                "map_at_5": 0.10795,
                "map_at_10": 0.12756,
                "map_at_25": 0.14424,
                "map_at_50": 0.15064,
                "map_at_100": 0.15504,
                "Recall_at_1": 0.06021,
                "Recall_at_5": 0.15003,
                "Recall_at_10": 0.21975,
                "Recall_at_25": 0.32649,
                "Recall_at_50": 0.45208,
                "Recall_at_100": 0.57702,
                "precision_at_1": 0.18447,
                "precision_at_5": 0.1165,
                "precision_at_10": 0.08932,
                "precision_at_25": 0.05359,
                "precision_at_50": 0.03495,
                "precision_at_100": 0.02204,
                "mrr": 0.26604
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.25961,
                "ndcg_at_1": 0.25,
                "ndcg_at_5": 0.24378,
                "ndcg_at_10": 0.25961,
                "ndcg_at_25": 0.29346,
                "ndcg_at_50": 0.31948,
                "ndcg_at_100": 0.33921,
                "map_at_1": 0.09782,
                "map_at_5": 0.17736,
                "map_at_10": 0.1946,
                "map_at_25": 0.20692,
                "map_at_50": 0.21364,
                "map_at_100": 0.21699,
                "Recall_at_1": 0.09782,
                "Recall_at_5": 0.23713,
                "Recall_at_10": 0.29404,
                "Recall_at_25": 0.39616,
                "Recall_at_50": 0.47324,
                "Recall_at_100": 0.54479,
                "precision_at_1": 0.25,
                "precision_at_5": 0.14655,
                "precision_at_10": 0.10172,
                "precision_at_25": 0.0569,
                "precision_at_50": 0.03776,
                "precision_at_100": 0.02336,
                "mrr": 0.33829
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16367,
                "ndcg_at_1": 0.12871,
                "ndcg_at_5": 0.1571,
                "ndcg_at_10": 0.16367,
                "ndcg_at_25": 0.18321,
                "ndcg_at_50": 0.19715,
                "ndcg_at_100": 0.21693,
                "map_at_1": 0.05739,
                "map_at_5": 0.10143,
                "map_at_10": 0.11166,
                "map_at_25": 0.12223,
                "map_at_50": 0.12599,
                "map_at_100": 0.12909,
                "Recall_at_1": 0.05739,
                "Recall_at_5": 0.15441,
                "Recall_at_10": 0.18714,
                "Recall_at_25": 0.26757,
                "Recall_at_50": 0.30896,
                "Recall_at_100": 0.37797,
                "precision_at_1": 0.12871,
                "precision_at_5": 0.09703,
                "precision_at_10": 0.07228,
                "precision_at_25": 0.04475,
                "precision_at_50": 0.0297,
                "precision_at_100": 0.02,
                "mrr": 0.21175
            }
        ]
    },
    "task_name": "BrightRetrieval"
}