{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.0951,
                "ndcg_at_1": 0.06838,
                "ndcg_at_5": 0.08241,
                "ndcg_at_10": 0.0951,
                "ndcg_at_25": 0.12899,
                "ndcg_at_50": 0.15906,
                "ndcg_at_100": 0.18507,
                "map_at_1": 0.02197,
                "map_at_5": 0.04573,
                "map_at_10": 0.05258,
                "map_at_25": 0.06334,
                "map_at_50": 0.06994,
                "map_at_100": 0.07332,
                "Recall_at_1": 0.02197,
                "Recall_at_5": 0.08217,
                "Recall_at_10": 0.12127,
                "Recall_at_25": 0.22812,
                "Recall_at_50": 0.33078,
                "Recall_at_100": 0.43512,
                "precision_at_1": 0.06838,
                "precision_at_5": 0.06154,
                "precision_at_10": 0.04872,
                "precision_at_25": 0.03829,
                "precision_at_50": 0.03026,
                "precision_at_100": 0.02111,
                "mrr": 0.1478
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.2415,
                "ndcg_at_1": 0.21552,
                "ndcg_at_5": 0.22844,
                "ndcg_at_10": 0.2415,
                "ndcg_at_25": 0.27338,
                "ndcg_at_50": 0.29409,
                "ndcg_at_100": 0.31828,
                "map_at_1": 0.10489,
                "map_at_5": 0.17411,
                "map_at_10": 0.18404,
                "map_at_25": 0.19599,
                "map_at_50": 0.20074,
                "map_at_100": 0.20473,
                "Recall_at_1": 0.10489,
                "Recall_at_5": 0.23096,
                "Recall_at_10": 0.27027,
                "Recall_at_25": 0.36391,
                "Recall_at_50": 0.42892,
                "Recall_at_100": 0.52148,
                "precision_at_1": 0.21552,
                "precision_at_5": 0.12586,
                "precision_at_10": 0.08621,
                "precision_at_25": 0.05207,
                "precision_at_50": 0.03328,
                "precision_at_100": 0.02147,
                "mrr": 0.31432
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.06084,
                "ndcg_at_1": 0.05405,
                "ndcg_at_5": 0.05721,
                "ndcg_at_10": 0.06084,
                "ndcg_at_25": 0.07551,
                "ndcg_at_50": 0.09014,
                "ndcg_at_100": 0.10797,
                "map_at_1": 0.01266,
                "map_at_5": 0.03464,
                "map_at_10": 0.03958,
                "map_at_25": 0.04373,
                "map_at_50": 0.04631,
                "map_at_100": 0.04838,
                "Recall_at_1": 0.01266,
                "Recall_at_5": 0.05615,
                "Recall_at_10": 0.07191,
                "Recall_at_25": 0.10982,
                "Recall_at_50": 0.15653,
                "Recall_at_100": 0.22169,
                "precision_at_1": 0.05405,
                "precision_at_5": 0.04505,
                "precision_at_10": 0.03153,
                "precision_at_25": 0.01946,
                "precision_at_50": 0.01423,
                "precision_at_100": 0.01054,
                "mrr": 0.09455
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.13267,
                "ndcg_at_1": 0.10185,
                "ndcg_at_5": 0.11046,
                "ndcg_at_10": 0.13267,
                "ndcg_at_25": 0.1717,
                "ndcg_at_50": 0.19537,
                "ndcg_at_100": 0.22828,
                "map_at_1": 0.04223,
                "map_at_5": 0.0776,
                "map_at_10": 0.08891,
                "map_at_25": 0.1008,
                "map_at_50": 0.10641,
                "map_at_100": 0.1115,
                "Recall_at_1": 0.04223,
                "Recall_at_5": 0.10983,
                "Recall_at_10": 0.16976,
                "Recall_at_25": 0.28501,
                "Recall_at_50": 0.36206,
                "Recall_at_100": 0.50349,
                "precision_at_1": 0.10185,
                "precision_at_5": 0.07037,
                "precision_at_10": 0.05741,
                "precision_at_25": 0.04259,
                "precision_at_50": 0.03074,
                "precision_at_100": 0.02185,
                "mrr": 0.18519
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17445,
                "ndcg_at_1": 0.15842,
                "ndcg_at_5": 0.16976,
                "ndcg_at_10": 0.17445,
                "ndcg_at_25": 0.18848,
                "ndcg_at_50": 0.20678,
                "ndcg_at_100": 0.23147,
                "map_at_1": 0.06658,
                "map_at_5": 0.10242,
                "map_at_10": 0.11736,
                "map_at_25": 0.13264,
                "map_at_50": 0.1381,
                "map_at_100": 0.14173,
                "Recall_at_1": 0.06658,
                "Recall_at_5": 0.13671,
                "Recall_at_10": 0.18446,
                "Recall_at_25": 0.24407,
                "Recall_at_50": 0.32101,
                "Recall_at_100": 0.43298,
                "precision_at_1": 0.15842,
                "precision_at_5": 0.11089,
                "precision_at_10": 0.08218,
                "precision_at_25": 0.05465,
                "precision_at_50": 0.03683,
                "precision_at_100": 0.02347,
                "mrr": 0.23066
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.12214,
                "ndcg_at_1": 0.13861,
                "ndcg_at_5": 0.11712,
                "ndcg_at_10": 0.12214,
                "ndcg_at_25": 0.13671,
                "ndcg_at_50": 0.14617,
                "ndcg_at_100": 0.16524,
                "map_at_1": 0.04191,
                "map_at_5": 0.06919,
                "map_at_10": 0.07501,
                "map_at_25": 0.08151,
                "map_at_50": 0.08359,
                "map_at_100": 0.08595,
                "Recall_at_1": 0.04191,
                "Recall_at_5": 0.1068,
                "Recall_at_10": 0.14432,
                "Recall_at_25": 0.20119,
                "Recall_at_50": 0.23352,
                "Recall_at_100": 0.3129,
                "precision_at_1": 0.13861,
                "precision_at_5": 0.07327,
                "precision_at_10": 0.0505,
                "precision_at_25": 0.03129,
                "precision_at_50": 0.01921,
                "precision_at_100": 0.01366,
                "mrr": 0.19682
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.05511,
                "ndcg_at_1": 0.03077,
                "ndcg_at_5": 0.04458,
                "ndcg_at_10": 0.05511,
                "ndcg_at_25": 0.0799,
                "ndcg_at_50": 0.09675,
                "ndcg_at_100": 0.10927,
                "map_at_1": 0.01282,
                "map_at_5": 0.03679,
                "map_at_10": 0.04043,
                "map_at_25": 0.04625,
                "map_at_50": 0.04898,
                "map_at_100": 0.05027,
                "Recall_at_1": 0.01282,
                "Recall_at_5": 0.05641,
                "Recall_at_10": 0.08718,
                "Recall_at_25": 0.18462,
                "Recall_at_50": 0.26154,
                "Recall_at_100": 0.32564,
                "precision_at_1": 0.03077,
                "precision_at_5": 0.02154,
                "precision_at_10": 0.01538,
                "precision_at_25": 0.01108,
                "precision_at_50": 0.008,
                "precision_at_100": 0.00523,
                "mrr": 0.06313
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.05645,
                "ndcg_at_1": 0.03571,
                "ndcg_at_5": 0.05053,
                "ndcg_at_10": 0.05645,
                "ndcg_at_25": 0.06144,
                "ndcg_at_50": 0.09779,
                "ndcg_at_100": 0.14662,
                "map_at_1": 0.00185,
                "map_at_5": 0.00705,
                "map_at_10": 0.00988,
                "map_at_25": 0.01387,
                "map_at_50": 0.0191,
                "map_at_100": 0.02604,
                "Recall_at_1": 0.00185,
                "Recall_at_5": 0.01414,
                "Recall_at_10": 0.0301,
                "Recall_at_25": 0.06894,
                "Recall_at_50": 0.13701,
                "Recall_at_100": 0.24116,
                "precision_at_1": 0.03571,
                "precision_at_5": 0.05179,
                "precision_at_10": 0.05893,
                "precision_at_25": 0.05107,
                "precision_at_50": 0.05643,
                "precision_at_100": 0.05143,
                "mrr": 0.15586
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.11959,
                "ndcg_at_1": 0.09709,
                "ndcg_at_5": 0.0986,
                "ndcg_at_10": 0.11959,
                "ndcg_at_25": 0.14744,
                "ndcg_at_50": 0.16986,
                "ndcg_at_100": 0.19105,
                "map_at_1": 0.0281,
                "map_at_5": 0.05951,
                "map_at_10": 0.07184,
                "map_at_25": 0.08103,
                "map_at_50": 0.08553,
                "map_at_100": 0.08818,
                "Recall_at_1": 0.0281,
                "Recall_at_5": 0.09826,
                "Recall_at_10": 0.15148,
                "Recall_at_25": 0.23134,
                "Recall_at_50": 0.3096,
                "Recall_at_100": 0.39912,
                "precision_at_1": 0.09709,
                "precision_at_5": 0.07379,
                "precision_at_10": 0.05922,
                "precision_at_25": 0.03534,
                "precision_at_50": 0.02369,
                "precision_at_100": 0.01524,
                "mrr": 0.17529
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.12563,
                "ndcg_at_1": 0.11707,
                "ndcg_at_5": 0.12071,
                "ndcg_at_10": 0.12563,
                "ndcg_at_25": 0.13625,
                "ndcg_at_50": 0.14006,
                "ndcg_at_100": 0.1468,
                "map_at_1": 0.07317,
                "map_at_5": 0.10488,
                "map_at_10": 0.10697,
                "map_at_25": 0.11052,
                "map_at_50": 0.11115,
                "map_at_100": 0.11176,
                "Recall_at_1": 0.07317,
                "Recall_at_5": 0.13171,
                "Recall_at_10": 0.14593,
                "Recall_at_25": 0.18078,
                "Recall_at_50": 0.1972,
                "Recall_at_100": 0.23053,
                "precision_at_1": 0.11707,
                "precision_at_5": 0.04976,
                "precision_at_10": 0.02732,
                "precision_at_25": 0.01385,
                "precision_at_50": 0.00761,
                "precision_at_100": 0.00454,
                "mrr": 0.14654
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26681,
                "ndcg_at_1": 0.26761,
                "ndcg_at_5": 0.24867,
                "ndcg_at_10": 0.26681,
                "ndcg_at_25": 0.28846,
                "ndcg_at_50": 0.30709,
                "ndcg_at_100": 0.31797,
                "map_at_1": 0.14765,
                "map_at_5": 0.2081,
                "map_at_10": 0.21669,
                "map_at_25": 0.22326,
                "map_at_50": 0.22656,
                "map_at_100": 0.22765,
                "Recall_at_1": 0.14765,
                "Recall_at_5": 0.26761,
                "Recall_at_10": 0.31326,
                "Recall_at_25": 0.38979,
                "Recall_at_50": 0.47195,
                "Recall_at_100": 0.53263,
                "precision_at_1": 0.26761,
                "precision_at_5": 0.10704,
                "precision_at_10": 0.06338,
                "precision_at_25": 0.03042,
                "precision_at_50": 0.01817,
                "precision_at_100": 0.01007,
                "mrr": 0.33153
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16586,
                "ndcg_at_1": 0.17476,
                "ndcg_at_5": 0.16162,
                "ndcg_at_10": 0.16586,
                "ndcg_at_25": 0.18577,
                "ndcg_at_50": 0.20742,
                "ndcg_at_100": 0.22853,
                "map_at_1": 0.05968,
                "map_at_5": 0.09002,
                "map_at_10": 0.10014,
                "map_at_25": 0.11318,
                "map_at_50": 0.1211,
                "map_at_100": 0.1268,
                "Recall_at_1": 0.05968,
                "Recall_at_5": 0.12612,
                "Recall_at_10": 0.16238,
                "Recall_at_25": 0.2658,
                "Recall_at_50": 0.36389,
                "Recall_at_100": 0.44589,
                "precision_at_1": 0.17476,
                "precision_at_5": 0.09515,
                "precision_at_10": 0.07961,
                "precision_at_25": 0.05786,
                "precision_at_50": 0.04272,
                "precision_at_100": 0.02932,
                "mrr": 0.23032
            }
        ]
    },
    "task_name": "BrightRetrieval"
}