{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.08257,
                "ndcg_at_1": 0.0991,
                "ndcg_at_5": 0.0763,
                "ndcg_at_10": 0.08257,
                "ndcg_at_25": 0.10308,
                "ndcg_at_50": 0.12103,
                "ndcg_at_100": 0.13687,
                "map_at_1": 0.01802,
                "map_at_5": 0.04452,
                "map_at_10": 0.05582,
                "map_at_25": 0.06044,
                "map_at_50": 0.06398,
                "map_at_100": 0.06585,
                "Recall_at_1": 0.01802,
                "Recall_at_5": 0.05888,
                "Recall_at_10": 0.08923,
                "Recall_at_25": 0.1487,
                "Recall_at_50": 0.20699,
                "Recall_at_100": 0.2707,
                "precision_at_1": 0.0991,
                "precision_at_5": 0.06306,
                "precision_at_10": 0.04685,
                "precision_at_25": 0.02739,
                "precision_at_50": 0.0191,
                "precision_at_100": 0.01216,
                "mrr": 0.13945
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17389,
                "ndcg_at_1": 0.13861,
                "ndcg_at_5": 0.15643,
                "ndcg_at_10": 0.17389,
                "ndcg_at_25": 0.19127,
                "ndcg_at_50": 0.20635,
                "ndcg_at_100": 0.23543,
                "map_at_1": 0.05817,
                "map_at_5": 0.10448,
                "map_at_10": 0.11768,
                "map_at_25": 0.1258,
                "map_at_50": 0.12921,
                "map_at_100": 0.13322,
                "Recall_at_1": 0.05817,
                "Recall_at_5": 0.1627,
                "Recall_at_10": 0.21995,
                "Recall_at_25": 0.2789,
                "Recall_at_50": 0.32935,
                "Recall_at_100": 0.45481,
                "precision_at_1": 0.13861,
                "precision_at_5": 0.08713,
                "precision_at_10": 0.06733,
                "precision_at_25": 0.04158,
                "precision_at_50": 0.02693,
                "precision_at_100": 0.01931,
                "mrr": 0.22131
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.22806,
                "ndcg_at_1": 0.17476,
                "ndcg_at_5": 0.20667,
                "ndcg_at_10": 0.22806,
                "ndcg_at_25": 0.24681,
                "ndcg_at_50": 0.27171,
                "ndcg_at_100": 0.30219,
                "map_at_1": 0.08721,
                "map_at_5": 0.12838,
                "map_at_10": 0.14898,
                "map_at_25": 0.16229,
                "map_at_50": 0.17092,
                "map_at_100": 0.17658,
                "Recall_at_1": 0.08721,
                "Recall_at_5": 0.18197,
                "Recall_at_10": 0.25367,
                "Recall_at_25": 0.34204,
                "Recall_at_50": 0.4353,
                "Recall_at_100": 0.57282,
                "precision_at_1": 0.17476,
                "precision_at_5": 0.12816,
                "precision_at_10": 0.10583,
                "precision_at_25": 0.06835,
                "precision_at_50": 0.04835,
                "precision_at_100": 0.03233,
                "mrr": 0.26723
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19062,
                "ndcg_at_1": 0.20513,
                "ndcg_at_5": 0.17089,
                "ndcg_at_10": 0.19062,
                "ndcg_at_25": 0.22377,
                "ndcg_at_50": 0.24981,
                "ndcg_at_100": 0.27345,
                "map_at_1": 0.06802,
                "map_at_5": 0.10831,
                "map_at_10": 0.12338,
                "map_at_25": 0.13868,
                "map_at_50": 0.14635,
                "map_at_100": 0.15116,
                "Recall_at_1": 0.06802,
                "Recall_at_5": 0.14832,
                "Recall_at_10": 0.21065,
                "Recall_at_25": 0.31548,
                "Recall_at_50": 0.40408,
                "Recall_at_100": 0.48678,
                "precision_at_1": 0.20513,
                "precision_at_5": 0.11111,
                "precision_at_10": 0.08803,
                "precision_at_25": 0.05949,
                "precision_at_50": 0.04103,
                "precision_at_100": 0.02761,
                "mrr": 0.27627
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27503,
                "ndcg_at_1": 0.28169,
                "ndcg_at_5": 0.26237,
                "ndcg_at_10": 0.27503,
                "ndcg_at_25": 0.30429,
                "ndcg_at_50": 0.31819,
                "ndcg_at_100": 0.33002,
                "map_at_1": 0.14941,
                "map_at_5": 0.21942,
                "map_at_10": 0.22533,
                "map_at_25": 0.23373,
                "map_at_50": 0.23634,
                "map_at_100": 0.23769,
                "Recall_at_1": 0.14941,
                "Recall_at_5": 0.2831,
                "Recall_at_10": 0.31761,
                "Recall_at_25": 0.41667,
                "Recall_at_50": 0.48028,
                "Recall_at_100": 0.54249,
                "precision_at_1": 0.28169,
                "precision_at_5": 0.11408,
                "precision_at_10": 0.06338,
                "precision_at_25": 0.03296,
                "precision_at_50": 0.01845,
                "precision_at_100": 0.01042,
                "mrr": 0.34829
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.14592,
                "ndcg_at_1": 0.15122,
                "ndcg_at_5": 0.13586,
                "ndcg_at_10": 0.14592,
                "ndcg_at_25": 0.15695,
                "ndcg_at_50": 0.163,
                "ndcg_at_100": 0.17461,
                "map_at_1": 0.0813,
                "map_at_5": 0.11417,
                "map_at_10": 0.11859,
                "map_at_25": 0.12247,
                "map_at_50": 0.12342,
                "map_at_100": 0.12459,
                "Recall_at_1": 0.0813,
                "Recall_at_5": 0.14309,
                "Recall_at_10": 0.16626,
                "Recall_at_25": 0.2007,
                "Recall_at_50": 0.22671,
                "Recall_at_100": 0.28676,
                "precision_at_1": 0.15122,
                "precision_at_5": 0.05366,
                "precision_at_10": 0.03317,
                "precision_at_25": 0.01678,
                "precision_at_50": 0.00946,
                "precision_at_100": 0.0059,
                "mrr": 0.18716
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27434,
                "ndcg_at_1": 0.23762,
                "ndcg_at_5": 0.24473,
                "ndcg_at_10": 0.27434,
                "ndcg_at_25": 0.30452,
                "ndcg_at_50": 0.32822,
                "ndcg_at_100": 0.35266,
                "map_at_1": 0.087,
                "map_at_5": 0.15788,
                "map_at_10": 0.1884,
                "map_at_25": 0.20809,
                "map_at_50": 0.21464,
                "map_at_100": 0.21853,
                "Recall_at_1": 0.087,
                "Recall_at_5": 0.24849,
                "Recall_at_10": 0.35596,
                "Recall_at_25": 0.46197,
                "Recall_at_50": 0.55712,
                "Recall_at_100": 0.66271,
                "precision_at_1": 0.23762,
                "precision_at_5": 0.14059,
                "precision_at_10": 0.1099,
                "precision_at_25": 0.0705,
                "precision_at_50": 0.04455,
                "precision_at_100": 0.02812,
                "mrr": 0.33809
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21909,
                "ndcg_at_1": 0.19417,
                "ndcg_at_5": 0.18784,
                "ndcg_at_10": 0.21909,
                "ndcg_at_25": 0.25533,
                "ndcg_at_50": 0.28729,
                "ndcg_at_100": 0.31597,
                "map_at_1": 0.05886,
                "map_at_5": 0.12171,
                "map_at_10": 0.14403,
                "map_at_25": 0.15911,
                "map_at_50": 0.16671,
                "map_at_100": 0.17088,
                "Recall_at_1": 0.05886,
                "Recall_at_5": 0.1856,
                "Recall_at_10": 0.27261,
                "Recall_at_25": 0.37592,
                "Recall_at_50": 0.48928,
                "Recall_at_100": 0.61405,
                "precision_at_1": 0.19417,
                "precision_at_5": 0.13398,
                "precision_at_10": 0.1,
                "precision_at_25": 0.05709,
                "precision_at_50": 0.03689,
                "precision_at_100": 0.02252,
                "mrr": 0.29708
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.06504,
                "ndcg_at_1": 0.01538,
                "ndcg_at_5": 0.03467,
                "ndcg_at_10": 0.06504,
                "ndcg_at_25": 0.07933,
                "ndcg_at_50": 0.0857,
                "ndcg_at_100": 0.10294,
                "map_at_1": 0.00769,
                "map_at_5": 0.02628,
                "map_at_10": 0.03756,
                "map_at_25": 0.04211,
                "map_at_50": 0.04313,
                "map_at_100": 0.04477,
                "Recall_at_1": 0.00769,
                "Recall_at_5": 0.04359,
                "Recall_at_10": 0.13077,
                "Recall_at_25": 0.18205,
                "Recall_at_50": 0.21026,
                "Recall_at_100": 0.30308,
                "precision_at_1": 0.01538,
                "precision_at_5": 0.01846,
                "precision_at_10": 0.02154,
                "precision_at_25": 0.01169,
                "precision_at_50": 0.00677,
                "precision_at_100": 0.00492,
                "mrr": 0.06335
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.3435,
                "ndcg_at_1": 0.32759,
                "ndcg_at_5": 0.31864,
                "ndcg_at_10": 0.3435,
                "ndcg_at_25": 0.38738,
                "ndcg_at_50": 0.41378,
                "ndcg_at_100": 0.44301,
                "map_at_1": 0.13935,
                "map_at_5": 0.23518,
                "map_at_10": 0.26408,
                "map_at_25": 0.28424,
                "map_at_50": 0.29077,
                "map_at_100": 0.29557,
                "Recall_at_1": 0.13935,
                "Recall_at_5": 0.30468,
                "Recall_at_10": 0.38013,
                "Recall_at_25": 0.50794,
                "Recall_at_50": 0.59737,
                "Recall_at_100": 0.71158,
                "precision_at_1": 0.32759,
                "precision_at_5": 0.1931,
                "precision_at_10": 0.13793,
                "precision_at_25": 0.08172,
                "precision_at_50": 0.04914,
                "precision_at_100": 0.03026,
                "mrr": 0.43494
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.18819,
                "ndcg_at_1": 0.14815,
                "ndcg_at_5": 0.16818,
                "ndcg_at_10": 0.18819,
                "ndcg_at_25": 0.23491,
                "ndcg_at_50": 0.26021,
                "ndcg_at_100": 0.28983,
                "map_at_1": 0.04421,
                "map_at_5": 0.10319,
                "map_at_10": 0.1219,
                "map_at_25": 0.14211,
                "map_at_50": 0.14887,
                "map_at_100": 0.1535,
                "Recall_at_1": 0.04421,
                "Recall_at_5": 0.1681,
                "Recall_at_10": 0.23879,
                "Recall_at_25": 0.37314,
                "Recall_at_50": 0.45944,
                "Recall_at_100": 0.58718,
                "precision_at_1": 0.14815,
                "precision_at_5": 0.12222,
                "precision_at_10": 0.09167,
                "precision_at_25": 0.06519,
                "precision_at_50": 0.04222,
                "precision_at_100": 0.02741,
                "mrr": 0.24882
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.05023,
                "ndcg_at_1": 0.07143,
                "ndcg_at_5": 0.05247,
                "ndcg_at_10": 0.05023,
                "ndcg_at_25": 0.0521,
                "ndcg_at_50": 0.07002,
                "ndcg_at_100": 0.10387,
                "map_at_1": 0.00387,
                "map_at_5": 0.00791,
                "map_at_10": 0.01098,
                "map_at_25": 0.01449,
                "map_at_50": 0.01717,
                "map_at_100": 0.02114,
                "Recall_at_1": 0.00387,
                "Recall_at_5": 0.01372,
                "Recall_at_10": 0.02537,
                "Recall_at_25": 0.05122,
                "Recall_at_50": 0.08538,
                "Recall_at_100": 0.15966,
                "precision_at_1": 0.07143,
                "precision_at_5": 0.04821,
                "precision_at_10": 0.04643,
                "precision_at_25": 0.04036,
                "precision_at_50": 0.03518,
                "precision_at_100": 0.03268,
                "mrr": 0.14094
            }
        ]
    },
    "task_name": "BrightRetrieval"
}