{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.0132,
                "ndcg_at_1": 0.01786,
                "ndcg_at_5": 0.01408,
                "ndcg_at_10": 0.0132,
                "ndcg_at_25": 0.01425,
                "ndcg_at_50": 0.02222,
                "ndcg_at_100": 0.03378,
                "map_at_1": 0.00083,
                "map_at_5": 0.00229,
                "map_at_10": 0.00292,
                "map_at_25": 0.00408,
                "map_at_50": 0.00503,
                "map_at_100": 0.00595,
                "Recall_at_1": 0.00083,
                "Recall_at_5": 0.00311,
                "Recall_at_10": 0.00669,
                "Recall_at_25": 0.01462,
                "Recall_at_50": 0.0301,
                "Recall_at_100": 0.05651,
                "precision_at_1": 0.01786,
                "precision_at_5": 0.0125,
                "precision_at_10": 0.01161,
                "precision_at_25": 0.01071,
                "precision_at_50": 0.01125,
                "precision_at_100": 0.01054,
                "mrr": 0.04477
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.13157,
                "ndcg_at_1": 0.08333,
                "ndcg_at_5": 0.11173,
                "ndcg_at_10": 0.13157,
                "ndcg_at_25": 0.16011,
                "ndcg_at_50": 0.19076,
                "ndcg_at_100": 0.21917,
                "map_at_1": 0.03183,
                "map_at_5": 0.07121,
                "map_at_10": 0.08336,
                "map_at_25": 0.09356,
                "map_at_50": 0.10009,
                "map_at_100": 0.10451,
                "Recall_at_1": 0.03183,
                "Recall_at_5": 0.12043,
                "Recall_at_10": 0.17421,
                "Recall_at_25": 0.25973,
                "Recall_at_50": 0.36786,
                "Recall_at_100": 0.4808,
                "precision_at_1": 0.08333,
                "precision_at_5": 0.07778,
                "precision_at_10": 0.06296,
                "precision_at_25": 0.04074,
                "precision_at_50": 0.03037,
                "precision_at_100": 0.02167,
                "mrr": 0.17801
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.07941,
                "ndcg_at_1": 0.0991,
                "ndcg_at_5": 0.07495,
                "ndcg_at_10": 0.07941,
                "ndcg_at_25": 0.09417,
                "ndcg_at_50": 0.10657,
                "ndcg_at_100": 0.11902,
                "map_at_1": 0.02408,
                "map_at_5": 0.04431,
                "map_at_10": 0.05123,
                "map_at_25": 0.05714,
                "map_at_50": 0.05987,
                "map_at_100": 0.06132,
                "Recall_at_1": 0.02408,
                "Recall_at_5": 0.05566,
                "Recall_at_10": 0.08199,
                "Recall_at_25": 0.1161,
                "Recall_at_50": 0.15744,
                "Recall_at_100": 0.20308,
                "precision_at_1": 0.0991,
                "precision_at_5": 0.05586,
                "precision_at_10": 0.03964,
                "precision_at_25": 0.02378,
                "precision_at_50": 0.01568,
                "precision_at_100": 0.01036,
                "mrr": 0.13543
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15611,
                "ndcg_at_1": 0.14563,
                "ndcg_at_5": 0.13664,
                "ndcg_at_10": 0.15611,
                "ndcg_at_25": 0.19495,
                "ndcg_at_50": 0.23075,
                "ndcg_at_100": 0.25756,
                "map_at_1": 0.04049,
                "map_at_5": 0.0882,
                "map_at_10": 0.10276,
                "map_at_25": 0.11784,
                "map_at_50": 0.12527,
                "map_at_100": 0.12901,
                "Recall_at_1": 0.04049,
                "Recall_at_5": 0.13166,
                "Recall_at_10": 0.18762,
                "Recall_at_25": 0.28863,
                "Recall_at_50": 0.42292,
                "Recall_at_100": 0.53707,
                "precision_at_1": 0.14563,
                "precision_at_5": 0.09126,
                "precision_at_10": 0.06796,
                "precision_at_25": 0.04466,
                "precision_at_50": 0.03126,
                "precision_at_100": 0.01961,
                "mrr": 0.23036
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.11211,
                "ndcg_at_1": 0.05983,
                "ndcg_at_5": 0.09617,
                "ndcg_at_10": 0.11211,
                "ndcg_at_25": 0.137,
                "ndcg_at_50": 0.16901,
                "ndcg_at_100": 0.19051,
                "map_at_1": 0.01741,
                "map_at_5": 0.05401,
                "map_at_10": 0.0646,
                "map_at_25": 0.07426,
                "map_at_50": 0.08125,
                "map_at_100": 0.08539,
                "Recall_at_1": 0.01741,
                "Recall_at_5": 0.10057,
                "Recall_at_10": 0.15076,
                "Recall_at_25": 0.22258,
                "Recall_at_50": 0.33436,
                "Recall_at_100": 0.40595,
                "precision_at_1": 0.05983,
                "precision_at_5": 0.07179,
                "precision_at_10": 0.05726,
                "precision_at_25": 0.04137,
                "precision_at_50": 0.03231,
                "precision_at_100": 0.02239,
                "mrr": 0.15025
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.09287,
                "ndcg_at_1": 0.03077,
                "ndcg_at_5": 0.06207,
                "ndcg_at_10": 0.09287,
                "ndcg_at_25": 0.11381,
                "ndcg_at_50": 0.12447,
                "ndcg_at_100": 0.1297,
                "map_at_1": 0.01282,
                "map_at_5": 0.04667,
                "map_at_10": 0.05968,
                "map_at_25": 0.06529,
                "map_at_50": 0.06699,
                "map_at_100": 0.06743,
                "Recall_at_1": 0.01282,
                "Recall_at_5": 0.08718,
                "Recall_at_10": 0.17308,
                "Recall_at_25": 0.25256,
                "Recall_at_50": 0.3,
                "Recall_at_100": 0.32821,
                "precision_at_1": 0.03077,
                "precision_at_5": 0.03077,
                "precision_at_10": 0.03077,
                "precision_at_25": 0.01662,
                "precision_at_50": 0.01015,
                "precision_at_100": 0.00554,
                "mrr": 0.08438
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21941,
                "ndcg_at_1": 0.15842,
                "ndcg_at_5": 0.19923,
                "ndcg_at_10": 0.21941,
                "ndcg_at_25": 0.24319,
                "ndcg_at_50": 0.26688,
                "ndcg_at_100": 0.28883,
                "map_at_1": 0.08181,
                "map_at_5": 0.13751,
                "map_at_10": 0.15688,
                "map_at_25": 0.17208,
                "map_at_50": 0.17822,
                "map_at_100": 0.18169,
                "Recall_at_1": 0.08181,
                "Recall_at_5": 0.19541,
                "Recall_at_10": 0.26752,
                "Recall_at_25": 0.36974,
                "Recall_at_50": 0.4575,
                "Recall_at_100": 0.55088,
                "precision_at_1": 0.15842,
                "precision_at_5": 0.11881,
                "precision_at_10": 0.09406,
                "precision_at_25": 0.05465,
                "precision_at_50": 0.03703,
                "precision_at_100": 0.02386,
                "mrr": 0.25185
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15987,
                "ndcg_at_1": 0.1068,
                "ndcg_at_5": 0.14432,
                "ndcg_at_10": 0.15987,
                "ndcg_at_25": 0.17623,
                "ndcg_at_50": 0.19771,
                "ndcg_at_100": 0.22671,
                "map_at_1": 0.05829,
                "map_at_5": 0.08684,
                "map_at_10": 0.09866,
                "map_at_25": 0.10978,
                "map_at_50": 0.11621,
                "map_at_100": 0.12153,
                "Recall_at_1": 0.05829,
                "Recall_at_5": 0.12156,
                "Recall_at_10": 0.17536,
                "Recall_at_25": 0.25429,
                "Recall_at_50": 0.35542,
                "Recall_at_100": 0.46725,
                "precision_at_1": 0.1068,
                "precision_at_5": 0.08738,
                "precision_at_10": 0.07573,
                "precision_at_25": 0.05359,
                "precision_at_50": 0.03806,
                "precision_at_100": 0.02767,
                "mrr": 0.19096
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.11453,
                "ndcg_at_1": 0.09901,
                "ndcg_at_5": 0.0955,
                "ndcg_at_10": 0.11453,
                "ndcg_at_25": 0.13231,
                "ndcg_at_50": 0.15001,
                "ndcg_at_100": 0.16753,
                "map_at_1": 0.04476,
                "map_at_5": 0.06848,
                "map_at_10": 0.07583,
                "map_at_25": 0.08223,
                "map_at_50": 0.08507,
                "map_at_100": 0.08746,
                "Recall_at_1": 0.04476,
                "Recall_at_5": 0.10253,
                "Recall_at_10": 0.15643,
                "Recall_at_25": 0.21141,
                "Recall_at_50": 0.27814,
                "Recall_at_100": 0.34725,
                "precision_at_1": 0.09901,
                "precision_at_5": 0.0495,
                "precision_at_10": 0.04455,
                "precision_at_25": 0.0301,
                "precision_at_50": 0.02099,
                "precision_at_100": 0.01446,
                "mrr": 0.15261
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.20002,
                "ndcg_at_1": 0.19014,
                "ndcg_at_5": 0.18548,
                "ndcg_at_10": 0.20002,
                "ndcg_at_25": 0.22064,
                "ndcg_at_50": 0.24221,
                "ndcg_at_100": 0.25783,
                "map_at_1": 0.09425,
                "map_at_5": 0.14765,
                "map_at_10": 0.157,
                "map_at_25": 0.16252,
                "map_at_50": 0.16606,
                "map_at_100": 0.16762,
                "Recall_at_1": 0.09425,
                "Recall_at_5": 0.20141,
                "Recall_at_10": 0.23638,
                "Recall_at_25": 0.31174,
                "Recall_at_50": 0.41385,
                "Recall_at_100": 0.49977,
                "precision_at_1": 0.19014,
                "precision_at_5": 0.09014,
                "precision_at_10": 0.05352,
                "precision_at_25": 0.0262,
                "precision_at_50": 0.01592,
                "precision_at_100": 0.0093,
                "mrr": 0.25825
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21517,
                "ndcg_at_1": 0.14655,
                "ndcg_at_5": 0.18272,
                "ndcg_at_10": 0.21517,
                "ndcg_at_25": 0.25012,
                "ndcg_at_50": 0.27743,
                "ndcg_at_100": 0.30445,
                "map_at_1": 0.07595,
                "map_at_5": 0.13375,
                "map_at_10": 0.15188,
                "map_at_25": 0.1662,
                "map_at_50": 0.17246,
                "map_at_100": 0.17687,
                "Recall_at_1": 0.07595,
                "Recall_at_5": 0.19047,
                "Recall_at_10": 0.27768,
                "Recall_at_25": 0.37705,
                "Recall_at_50": 0.46157,
                "Recall_at_100": 0.56236,
                "precision_at_1": 0.14655,
                "precision_at_5": 0.11207,
                "precision_at_10": 0.08534,
                "precision_at_25": 0.05483,
                "precision_at_50": 0.03672,
                "precision_at_100": 0.02388,
                "mrr": 0.25966
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.20066,
                "ndcg_at_1": 0.20488,
                "ndcg_at_5": 0.18937,
                "ndcg_at_10": 0.20066,
                "ndcg_at_25": 0.21043,
                "ndcg_at_50": 0.21865,
                "ndcg_at_100": 0.23257,
                "map_at_1": 0.11423,
                "map_at_5": 0.16206,
                "map_at_10": 0.16762,
                "map_at_25": 0.1709,
                "map_at_50": 0.17222,
                "map_at_100": 0.17344,
                "Recall_at_1": 0.11423,
                "Recall_at_5": 0.19634,
                "Recall_at_10": 0.22764,
                "Recall_at_25": 0.26005,
                "Recall_at_50": 0.29803,
                "Recall_at_100": 0.37474,
                "precision_at_1": 0.20488,
                "precision_at_5": 0.07805,
                "precision_at_10": 0.04439,
                "precision_at_25": 0.02068,
                "precision_at_50": 0.01171,
                "precision_at_100": 0.00717,
                "mrr": 0.247
            }
        ]
    },
    "task_name": "BrightRetrieval"
}