{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19792,
                "ndcg_at_1": 0.13889,
                "ndcg_at_5": 0.18122,
                "ndcg_at_10": 0.19792,
                "ndcg_at_25": 0.23276,
                "ndcg_at_50": 0.26542,
                "ndcg_at_100": 0.28998,
                "map_at_1": 0.06657,
                "map_at_5": 0.12504,
                "map_at_10": 0.14038,
                "map_at_25": 0.15611,
                "map_at_50": 0.16392,
                "map_at_100": 0.16868,
                "Recall_at_1": 0.06657,
                "Recall_at_5": 0.19805,
                "Recall_at_10": 0.25293,
                "Recall_at_25": 0.34917,
                "Recall_at_50": 0.45587,
                "Recall_at_100": 0.54509,
                "precision_at_1": 0.13889,
                "precision_at_5": 0.10556,
                "precision_at_10": 0.07685,
                "precision_at_25": 0.05185,
                "precision_at_50": 0.03833,
                "precision_at_100": 0.02509,
                "mrr": 0.24794
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.1784,
                "ndcg_at_1": 0.13592,
                "ndcg_at_5": 0.16477,
                "ndcg_at_10": 0.1784,
                "ndcg_at_25": 0.20288,
                "ndcg_at_50": 0.22449,
                "ndcg_at_100": 0.25286,
                "map_at_1": 0.03065,
                "map_at_5": 0.08053,
                "map_at_10": 0.0964,
                "map_at_25": 0.11468,
                "map_at_50": 0.12786,
                "map_at_100": 0.13672,
                "Recall_at_1": 0.03065,
                "Recall_at_5": 0.14801,
                "Recall_at_10": 0.21684,
                "Recall_at_25": 0.30859,
                "Recall_at_50": 0.39599,
                "Recall_at_100": 0.50856,
                "precision_at_1": 0.13592,
                "precision_at_5": 0.11456,
                "precision_at_10": 0.09029,
                "precision_at_25": 0.07262,
                "precision_at_50": 0.05728,
                "precision_at_100": 0.03932,
                "mrr": 0.22047
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.24046,
                "ndcg_at_1": 0.16923,
                "ndcg_at_5": 0.20344,
                "ndcg_at_10": 0.24046,
                "ndcg_at_25": 0.26562,
                "ndcg_at_50": 0.27958,
                "ndcg_at_100": 0.29035,
                "map_at_1": 0.08513,
                "map_at_5": 0.15726,
                "map_at_10": 0.17392,
                "map_at_25": 0.18189,
                "map_at_50": 0.18447,
                "map_at_100": 0.18573,
                "Recall_at_1": 0.08513,
                "Recall_at_5": 0.25821,
                "Recall_at_10": 0.36718,
                "Recall_at_25": 0.45308,
                "Recall_at_50": 0.51718,
                "Recall_at_100": 0.56718,
                "precision_at_1": 0.16923,
                "precision_at_5": 0.10154,
                "precision_at_10": 0.06615,
                "precision_at_25": 0.03262,
                "precision_at_50": 0.01815,
                "precision_at_100": 0.01031,
                "mrr": 0.25673
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.07433,
                "ndcg_at_1": 0.08108,
                "ndcg_at_5": 0.07064,
                "ndcg_at_10": 0.07433,
                "ndcg_at_25": 0.09313,
                "ndcg_at_50": 0.10152,
                "ndcg_at_100": 0.12542,
                "map_at_1": 0.01845,
                "map_at_5": 0.03769,
                "map_at_10": 0.04559,
                "map_at_25": 0.052,
                "map_at_50": 0.05374,
                "map_at_100": 0.05636,
                "Recall_at_1": 0.01845,
                "Recall_at_5": 0.0562,
                "Recall_at_10": 0.07658,
                "Recall_at_25": 0.12629,
                "Recall_at_50": 0.1501,
                "Recall_at_100": 0.24512,
                "precision_at_1": 0.08108,
                "precision_at_5": 0.05766,
                "precision_at_10": 0.04234,
                "precision_at_25": 0.02631,
                "precision_at_50": 0.01604,
                "precision_at_100": 0.01216,
                "mrr": 0.13494
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23054,
                "ndcg_at_1": 0.23415,
                "ndcg_at_5": 0.2189,
                "ndcg_at_10": 0.23054,
                "ndcg_at_25": 0.24711,
                "ndcg_at_50": 0.25622,
                "ndcg_at_100": 0.26416,
                "map_at_1": 0.1435,
                "map_at_5": 0.19437,
                "map_at_10": 0.20143,
                "map_at_25": 0.20623,
                "map_at_50": 0.20776,
                "map_at_100": 0.20875,
                "Recall_at_1": 0.1435,
                "Recall_at_5": 0.22346,
                "Recall_at_10": 0.2511,
                "Recall_at_25": 0.30639,
                "Recall_at_50": 0.34541,
                "Recall_at_100": 0.3842,
                "precision_at_1": 0.23415,
                "precision_at_5": 0.08976,
                "precision_at_10": 0.0522,
                "precision_at_25": 0.02576,
                "precision_at_50": 0.01454,
                "precision_at_100": 0.00815,
                "mrr": 0.27233
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.1897,
                "ndcg_at_1": 0.14851,
                "ndcg_at_5": 0.15717,
                "ndcg_at_10": 0.1897,
                "ndcg_at_25": 0.23487,
                "ndcg_at_50": 0.26117,
                "ndcg_at_100": 0.28603,
                "map_at_1": 0.031,
                "map_at_5": 0.0819,
                "map_at_10": 0.11102,
                "map_at_25": 0.14103,
                "map_at_50": 0.15069,
                "map_at_100": 0.15475,
                "Recall_at_1": 0.031,
                "Recall_at_5": 0.14009,
                "Recall_at_10": 0.25315,
                "Recall_at_25": 0.41831,
                "Recall_at_50": 0.51822,
                "Recall_at_100": 0.62971,
                "precision_at_1": 0.14851,
                "precision_at_5": 0.11485,
                "precision_at_10": 0.10297,
                "precision_at_25": 0.07327,
                "precision_at_50": 0.04832,
                "precision_at_100": 0.02931,
                "mrr": 0.2308
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.12721,
                "ndcg_at_1": 0.11111,
                "ndcg_at_5": 0.10765,
                "ndcg_at_10": 0.12721,
                "ndcg_at_25": 0.15523,
                "ndcg_at_50": 0.18247,
                "ndcg_at_100": 0.21827,
                "map_at_1": 0.03861,
                "map_at_5": 0.06494,
                "map_at_10": 0.08067,
                "map_at_25": 0.09043,
                "map_at_50": 0.09741,
                "map_at_100": 0.10305,
                "Recall_at_1": 0.03861,
                "Recall_at_5": 0.09566,
                "Recall_at_10": 0.16033,
                "Recall_at_25": 0.24774,
                "Recall_at_50": 0.33745,
                "Recall_at_100": 0.48039,
                "precision_at_1": 0.11111,
                "precision_at_5": 0.07521,
                "precision_at_10": 0.05897,
                "precision_at_25": 0.04171,
                "precision_at_50": 0.03231,
                "precision_at_100": 0.02376,
                "mrr": 0.17565
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.01968,
                "ndcg_at_1": 0.01786,
                "ndcg_at_5": 0.01799,
                "ndcg_at_10": 0.01968,
                "ndcg_at_25": 0.03942,
                "ndcg_at_50": 0.07633,
                "ndcg_at_100": 0.13365,
                "map_at_1": 0.00132,
                "map_at_5": 0.00309,
                "map_at_10": 0.00415,
                "map_at_25": 0.00765,
                "map_at_50": 0.01248,
                "map_at_100": 0.01997,
                "Recall_at_1": 0.00132,
                "Recall_at_5": 0.00567,
                "Recall_at_10": 0.0109,
                "Recall_at_25": 0.04764,
                "Recall_at_50": 0.11412,
                "Recall_at_100": 0.23476,
                "precision_at_1": 0.01786,
                "precision_at_5": 0.01786,
                "precision_at_10": 0.02054,
                "precision_at_25": 0.04,
                "precision_at_50": 0.05143,
                "precision_at_100": 0.05339,
                "mrr": 0.07755
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27351,
                "ndcg_at_1": 0.24648,
                "ndcg_at_5": 0.25158,
                "ndcg_at_10": 0.27351,
                "ndcg_at_25": 0.30494,
                "ndcg_at_50": 0.32631,
                "ndcg_at_100": 0.34416,
                "map_at_1": 0.13298,
                "map_at_5": 0.20547,
                "map_at_10": 0.21883,
                "map_at_25": 0.2286,
                "map_at_50": 0.23194,
                "map_at_100": 0.23413,
                "Recall_at_1": 0.13298,
                "Recall_at_5": 0.273,
                "Recall_at_10": 0.32876,
                "Recall_at_25": 0.43791,
                "Recall_at_50": 0.53732,
                "Recall_at_100": 0.62852,
                "precision_at_1": 0.24648,
                "precision_at_5": 0.10986,
                "precision_at_10": 0.0662,
                "precision_at_25": 0.0338,
                "precision_at_50": 0.02,
                "precision_at_100": 0.01176,
                "mrr": 0.33949
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19486,
                "ndcg_at_1": 0.20388,
                "ndcg_at_5": 0.17288,
                "ndcg_at_10": 0.19486,
                "ndcg_at_25": 0.24114,
                "ndcg_at_50": 0.27392,
                "ndcg_at_100": 0.30191,
                "map_at_1": 0.05708,
                "map_at_5": 0.11764,
                "map_at_10": 0.13492,
                "map_at_25": 0.15565,
                "map_at_50": 0.16211,
                "map_at_100": 0.16617,
                "Recall_at_1": 0.05708,
                "Recall_at_5": 0.15784,
                "Recall_at_10": 0.2271,
                "Recall_at_25": 0.3494,
                "Recall_at_50": 0.47704,
                "Recall_at_100": 0.60072,
                "precision_at_1": 0.20388,
                "precision_at_5": 0.12621,
                "precision_at_10": 0.0932,
                "precision_at_25": 0.05981,
                "precision_at_50": 0.03728,
                "precision_at_100": 0.02272,
                "mrr": 0.27325
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26633,
                "ndcg_at_1": 0.25862,
                "ndcg_at_5": 0.25022,
                "ndcg_at_10": 0.26633,
                "ndcg_at_25": 0.3083,
                "ndcg_at_50": 0.33307,
                "ndcg_at_100": 0.3528,
                "map_at_1": 0.09955,
                "map_at_5": 0.18262,
                "map_at_10": 0.20185,
                "map_at_25": 0.21821,
                "map_at_50": 0.22451,
                "map_at_100": 0.22802,
                "Recall_at_1": 0.09955,
                "Recall_at_5": 0.24731,
                "Recall_at_10": 0.30552,
                "Recall_at_25": 0.42645,
                "Recall_at_50": 0.50116,
                "Recall_at_100": 0.56916,
                "precision_at_1": 0.25862,
                "precision_at_5": 0.15,
                "precision_at_10": 0.10345,
                "precision_at_25": 0.06138,
                "precision_at_50": 0.03966,
                "precision_at_100": 0.02466,
                "mrr": 0.34565
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16704,
                "ndcg_at_1": 0.15842,
                "ndcg_at_5": 0.1561,
                "ndcg_at_10": 0.16704,
                "ndcg_at_25": 0.19022,
                "ndcg_at_50": 0.20015,
                "ndcg_at_100": 0.22359,
                "map_at_1": 0.05129,
                "map_at_5": 0.09691,
                "map_at_10": 0.11005,
                "map_at_25": 0.12249,
                "map_at_50": 0.12509,
                "map_at_100": 0.12872,
                "Recall_at_1": 0.05129,
                "Recall_at_5": 0.1417,
                "Recall_at_10": 0.19792,
                "Recall_at_25": 0.28883,
                "Recall_at_50": 0.31839,
                "Recall_at_100": 0.41545,
                "precision_at_1": 0.15842,
                "precision_at_5": 0.09505,
                "precision_at_10": 0.07129,
                "precision_at_25": 0.04832,
                "precision_at_50": 0.0301,
                "precision_at_100": 0.02,
                "mrr": 0.23097
            }
        ]
    },
    "task_name": "BrightRetrieval"
}