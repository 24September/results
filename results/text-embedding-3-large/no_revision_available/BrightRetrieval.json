{
    "dataset_revision": "a75a0eb",
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.22224,
                "ndcg_at_1": 0.21951,
                "ndcg_at_5": 0.20378,
                "ndcg_at_10": 0.22224,
                "ndcg_at_25": 0.23573,
                "ndcg_at_50": 0.24994,
                "ndcg_at_100": 0.26006,
                "map_at_1": 0.13415,
                "map_at_5": 0.1777,
                "map_at_10": 0.18705,
                "map_at_25": 0.19144,
                "map_at_50": 0.1941,
                "map_at_100": 0.19516,
                "Recall_at_1": 0.13415,
                "Recall_at_5": 0.20923,
                "Recall_at_10": 0.25761,
                "Recall_at_25": 0.30436,
                "Recall_at_50": 0.36167,
                "Recall_at_100": 0.41305,
                "precision_at_1": 0.21951,
                "precision_at_5": 0.08293,
                "precision_at_10": 0.05122,
                "precision_at_25": 0.0242,
                "precision_at_50": 0.01483,
                "precision_at_100": 0.00854,
                "mrr": 0.2629
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23647,
                "ndcg_at_1": 0.23239,
                "ndcg_at_5": 0.2144,
                "ndcg_at_10": 0.23647,
                "ndcg_at_25": 0.26081,
                "ndcg_at_50": 0.28811,
                "ndcg_at_100": 0.30081,
                "map_at_1": 0.11596,
                "map_at_5": 0.17143,
                "map_at_10": 0.18143,
                "map_at_25": 0.18909,
                "map_at_50": 0.19353,
                "map_at_100": 0.19485,
                "Recall_at_1": 0.11596,
                "Recall_at_5": 0.23744,
                "Recall_at_10": 0.29425,
                "Recall_at_25": 0.37981,
                "Recall_at_50": 0.51127,
                "Recall_at_100": 0.57981,
                "precision_at_1": 0.23239,
                "precision_at_5": 0.10141,
                "precision_at_10": 0.06268,
                "precision_at_25": 0.03155,
                "precision_at_50": 0.01958,
                "precision_at_100": 0.01099,
                "mrr": 0.29801
            },
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.26275,
                "ndcg_at_1": 0.25862,
                "ndcg_at_5": 0.24356,
                "ndcg_at_10": 0.26275,
                "ndcg_at_25": 0.30751,
                "ndcg_at_50": 0.33605,
                "ndcg_at_100": 0.36427,
                "map_at_1": 0.09134,
                "map_at_5": 0.17095,
                "map_at_10": 0.1906,
                "map_at_25": 0.20926,
                "map_at_50": 0.21625,
                "map_at_100": 0.22169,
                "Recall_at_1": 0.09134,
                "Recall_at_5": 0.23237,
                "Recall_at_10": 0.30536,
                "Recall_at_25": 0.43403,
                "Recall_at_50": 0.52126,
                "Recall_at_100": 0.63136,
                "precision_at_1": 0.25862,
                "precision_at_5": 0.16034,
                "precision_at_10": 0.11034,
                "precision_at_25": 0.06862,
                "precision_at_50": 0.04466,
                "precision_at_100": 0.02793,
                "mrr": 0.35728
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27521,
                "ndcg_at_1": 0.19802,
                "ndcg_at_5": 0.23242,
                "ndcg_at_10": 0.27521,
                "ndcg_at_25": 0.30948,
                "ndcg_at_50": 0.33752,
                "ndcg_at_100": 0.36113,
                "map_at_1": 0.07751,
                "map_at_5": 0.15047,
                "map_at_10": 0.18458,
                "map_at_25": 0.20923,
                "map_at_50": 0.21651,
                "map_at_100": 0.22109,
                "Recall_at_1": 0.07751,
                "Recall_at_5": 0.22624,
                "Recall_at_10": 0.36022,
                "Recall_at_25": 0.4919,
                "Recall_at_50": 0.60947,
                "Recall_at_100": 0.68977,
                "precision_at_1": 0.19802,
                "precision_at_5": 0.14059,
                "precision_at_10": 0.12376,
                "precision_at_25": 0.07881,
                "precision_at_50": 0.04911,
                "precision_at_100": 0.03178,
                "mrr": 0.30944
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.12933,
                "ndcg_at_1": 0.10891,
                "ndcg_at_5": 0.11096,
                "ndcg_at_10": 0.12933,
                "ndcg_at_25": 0.13587,
                "ndcg_at_50": 0.15898,
                "ndcg_at_100": 0.18104,
                "map_at_1": 0.04158,
                "map_at_5": 0.06671,
                "map_at_10": 0.07954,
                "map_at_25": 0.08563,
                "map_at_50": 0.0899,
                "map_at_100": 0.09313,
                "Recall_at_1": 0.04158,
                "Recall_at_5": 0.10508,
                "Recall_at_10": 0.16212,
                "Recall_at_25": 0.19678,
                "Recall_at_50": 0.28366,
                "Recall_at_100": 0.36951,
                "precision_at_1": 0.10891,
                "precision_at_5": 0.06139,
                "precision_at_10": 0.05842,
                "precision_at_25": 0.03485,
                "precision_at_50": 0.02535,
                "precision_at_100": 0.01772,
                "mrr": 0.16922
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19982,
                "ndcg_at_1": 0.1165,
                "ndcg_at_5": 0.17602,
                "ndcg_at_10": 0.19982,
                "ndcg_at_25": 0.22142,
                "ndcg_at_50": 0.24219,
                "ndcg_at_100": 0.27349,
                "map_at_1": 0.05009,
                "map_at_5": 0.09812,
                "map_at_10": 0.11837,
                "map_at_25": 0.13479,
                "map_at_50": 0.14421,
                "map_at_100": 0.15229,
                "Recall_at_1": 0.05009,
                "Recall_at_5": 0.17168,
                "Recall_at_10": 0.24516,
                "Recall_at_25": 0.32798,
                "Recall_at_50": 0.41919,
                "Recall_at_100": 0.54084,
                "precision_at_1": 0.1165,
                "precision_at_5": 0.11068,
                "precision_at_10": 0.09806,
                "precision_at_25": 0.07029,
                "precision_at_50": 0.05029,
                "precision_at_100": 0.03592,
                "mrr": 0.22744
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.12493,
                "ndcg_at_1": 0.07692,
                "ndcg_at_5": 0.10677,
                "ndcg_at_10": 0.12493,
                "ndcg_at_25": 0.1511,
                "ndcg_at_50": 0.18374,
                "ndcg_at_100": 0.21524,
                "map_at_1": 0.0283,
                "map_at_5": 0.06219,
                "map_at_10": 0.0756,
                "map_at_25": 0.08619,
                "map_at_50": 0.09314,
                "map_at_100": 0.09855,
                "Recall_at_1": 0.0283,
                "Recall_at_5": 0.10561,
                "Recall_at_10": 0.15784,
                "Recall_at_25": 0.24637,
                "Recall_at_50": 0.35703,
                "Recall_at_100": 0.47309,
                "precision_at_1": 0.07692,
                "precision_at_5": 0.07863,
                "precision_at_10": 0.06325,
                "precision_at_25": 0.04308,
                "precision_at_50": 0.03316,
                "precision_at_100": 0.02376,
                "mrr": 0.16425
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.23671,
                "ndcg_at_1": 0.21359,
                "ndcg_at_5": 0.20361,
                "ndcg_at_10": 0.23671,
                "ndcg_at_25": 0.27364,
                "ndcg_at_50": 0.30807,
                "ndcg_at_100": 0.33871,
                "map_at_1": 0.05248,
                "map_at_5": 0.13102,
                "map_at_10": 0.16098,
                "map_at_25": 0.17878,
                "map_at_50": 0.1857,
                "map_at_100": 0.1905,
                "Recall_at_1": 0.05248,
                "Recall_at_5": 0.19159,
                "Recall_at_10": 0.2908,
                "Recall_at_25": 0.39162,
                "Recall_at_50": 0.52268,
                "Recall_at_100": 0.65567,
                "precision_at_1": 0.21359,
                "precision_at_5": 0.14951,
                "precision_at_10": 0.11359,
                "precision_at_25": 0.0633,
                "precision_at_50": 0.03942,
                "precision_at_100": 0.02447,
                "mrr": 0.31744
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.09251,
                "ndcg_at_1": 0.04615,
                "ndcg_at_5": 0.08016,
                "ndcg_at_10": 0.09251,
                "ndcg_at_25": 0.14118,
                "ndcg_at_50": 0.16418,
                "ndcg_at_100": 0.17535,
                "map_at_1": 0.02692,
                "map_at_5": 0.05923,
                "map_at_10": 0.06366,
                "map_at_25": 0.08056,
                "map_at_50": 0.08417,
                "map_at_100": 0.08512,
                "Recall_at_1": 0.02692,
                "Recall_at_5": 0.11154,
                "Recall_at_10": 0.14615,
                "Recall_at_25": 0.30436,
                "Recall_at_50": 0.41205,
                "Recall_at_100": 0.47154,
                "precision_at_1": 0.04615,
                "precision_at_5": 0.04,
                "precision_at_10": 0.02615,
                "precision_at_25": 0.02277,
                "precision_at_50": 0.01477,
                "precision_at_100": 0.00846,
                "mrr": 0.11222
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.02455,
                "ndcg_at_1": 0.01786,
                "ndcg_at_5": 0.02609,
                "ndcg_at_10": 0.02455,
                "ndcg_at_25": 0.03255,
                "ndcg_at_50": 0.05404,
                "ndcg_at_100": 0.08242,
                "map_at_1": 0.00114,
                "map_at_5": 0.00406,
                "map_at_10": 0.0052,
                "map_at_25": 0.00727,
                "map_at_50": 0.00964,
                "map_at_100": 0.01251,
                "Recall_at_1": 0.00114,
                "Recall_at_5": 0.00796,
                "Recall_at_10": 0.01339,
                "Recall_at_25": 0.03609,
                "Recall_at_50": 0.08291,
                "Recall_at_100": 0.14829,
                "precision_at_1": 0.01786,
                "precision_at_5": 0.02679,
                "precision_at_10": 0.02411,
                "precision_at_25": 0.0275,
                "precision_at_50": 0.02982,
                "precision_at_100": 0.02741,
                "mrr": 0.09083
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.2032,
                "ndcg_at_1": 0.15741,
                "ndcg_at_5": 0.17863,
                "ndcg_at_10": 0.2032,
                "ndcg_at_25": 0.2457,
                "ndcg_at_50": 0.27996,
                "ndcg_at_100": 0.31003,
                "map_at_1": 0.0631,
                "map_at_5": 0.11895,
                "map_at_10": 0.13885,
                "map_at_25": 0.15889,
                "map_at_50": 0.16902,
                "map_at_100": 0.17461,
                "Recall_at_1": 0.0631,
                "Recall_at_5": 0.18052,
                "Recall_at_10": 0.25103,
                "Recall_at_25": 0.36897,
                "Recall_at_50": 0.48573,
                "Recall_at_100": 0.59652,
                "precision_at_1": 0.15741,
                "precision_at_5": 0.11296,
                "precision_at_10": 0.08981,
                "precision_at_25": 0.06185,
                "precision_at_50": 0.04296,
                "precision_at_100": 0.02889,
                "mrr": 0.26195
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.08455,
                "ndcg_at_1": 0.10811,
                "ndcg_at_5": 0.08716,
                "ndcg_at_10": 0.08455,
                "ndcg_at_25": 0.10836,
                "ndcg_at_50": 0.1255,
                "ndcg_at_100": 0.14539,
                "map_at_1": 0.0207,
                "map_at_5": 0.04937,
                "map_at_10": 0.05619,
                "map_at_25": 0.06435,
                "map_at_50": 0.06724,
                "map_at_100": 0.06975,
                "Recall_at_1": 0.0207,
                "Recall_at_5": 0.06526,
                "Recall_at_10": 0.08124,
                "Recall_at_25": 0.14329,
                "Recall_at_50": 0.19654,
                "Recall_at_100": 0.27215,
                "precision_at_1": 0.10811,
                "precision_at_5": 0.07207,
                "precision_at_10": 0.04505,
                "precision_at_25": 0.02919,
                "precision_at_50": 0.01964,
                "precision_at_100": 0.01342,
                "mrr": 0.15804
            }
        ]
    },
    "task_name": "BrightRetrieval"
}